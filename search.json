[
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-1",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-1",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 1",
    "text": "Conteúdo - Unidade 1\n\nIntrodução à análise de dados\n\nConceitos básicos\nIntrodução a ferramentas [Python, NumPy, Pandas, Jupyter]\nTratamento de dados\n\nCarregamento, limpeza, transformação\n\nVisualização básica\n\nExploratory Data Analysis (EDA)\n\nEstatística descritiva\nAnálise de correlação\nAnálise exploratória"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-2",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-2",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 2",
    "text": "Conteúdo - Unidade 2\n\nInferência estatística\n\nSignificância estatística e amostragem\nIntervalos de confiança\nTestes de hipótese\nTestes de permutação e p-valor\n\nRegressão\n\nRegressão linear simples\nRegressão linear multivariada\nRegressão logística"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-3",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-3",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 3",
    "text": "Conteúdo - Unidade 3\n\nClustering\n\nMedidas de similaridade e divergência\nAgrupamento com K-means\nAgrupamento hierárquico\n\nVisualização de dados\nProjeto de análise de dados"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#avaliações",
    "href": "1-introducao/0-apresentacao.html#avaliações",
    "title": "Análise de dados",
    "section": "Avaliações",
    "text": "Avaliações\n\nUnidades 1 e 2:\n\nAtividades práticas de análise de dados\n\nRelatórios\nQuestionários\n\n\nUnidade 3:\n\nProjeto de análise de dados\n\nRelatório analítico (ex: blog post, artigo)\nAplicação web / mobile\nDashboard"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#referências-básicas",
    "href": "1-introducao/0-apresentacao.html#referências-básicas",
    "title": "Análise de dados",
    "section": "Referências básicas",
    "text": "Referências básicas\n\nPython for Data Analysis. McKinney. 3 ed, 2022 (online)\nThe Data Science Design Manual. Skienna. 2017 (pdf, slides)\nPython Data Science Handbook. VanderPlas. 2022 (online)\nPractical Statistics for Data Scientists. Bruce. 2 ed, 2020 (pdf)\nR for Data Science. Wickham. 2017 (online)\nThink Stats: Exploratory Data Analysis in Python. Downey, 2014 (online)"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#referências-complementares",
    "href": "1-introducao/0-apresentacao.html#referências-complementares",
    "title": "Análise de dados",
    "section": "Referências complementares",
    "text": "Referências complementares\n\nCiência de Dados com R (online)\nModern Dive: An Introduction to Statistical and Data sciences via R (online; slides)\nIntroductory Statistics with Randomization and Simulation\nExploratory Data Analysis with R\nR Programming for Data Science\nAn Introduction to Statistical Learning\nThe Art of Data Science\nOpenIntro Statistics"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#ambientes-virtuais",
    "href": "1-introducao/0-apresentacao.html#ambientes-virtuais",
    "title": "Análise de dados",
    "section": "Ambientes virtuais",
    "text": "Ambientes virtuais\n\nGoogle Classroom\n\nAvisos gerais, slides e outros materiais\nPrecisa estar logado com a conta do DCX\n\nDiscord\n\nAvisos, dúvidas, discussões\n\nGitHub Classroom\n\nMaterial para atividades práticas, envio de código e relatórios\nCriem uma conta no GitHub e aprendam git!"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#ferramentas-para-começar-a-brincar",
    "href": "1-introducao/0-apresentacao.html#ferramentas-para-começar-a-brincar",
    "title": "Análise de dados",
    "section": "Ferramentas para começar a brincar",
    "text": "Ferramentas para começar a brincar\n\nPython: linguagem de programação que usaremos no curso\nJupyter Notebook: criar documentos com código executável\nNumPy: biblioteca Python para computação numérica\nPandas: biblioteca Python para análise de dados\nMatplotlib, Seaborn: bibliotecas Python de visualização de dados\nVS Code: IDE usada nas aulas\n\nInstalar extensão Python for VS Code\n\nGoogle Colab: ambiente de execução de notebooks\n\nPode ser usado para executar código integrado ao Github\n\n\n\n\nProf. Marcus Carvalho @ DCX / CCAE / UFPB"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#tendências-de-busca",
    "href": "1-introducao/1-introducao-ad.html#tendências-de-busca",
    "title": "Análise de dados",
    "section": "Tendências de busca",
    "text": "Tendências de busca\n\nFonte: Google Trends"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#dados-to-informação-to-conhecimento-to-sabedoria",
    "href": "1-introducao/1-introducao-ad.html#dados-to-informação-to-conhecimento-to-sabedoria",
    "title": "Análise de dados",
    "section": "Dados \\(\\to\\) Informação \\(\\to\\) Conhecimento \\(\\to\\) Sabedoria",
    "text": "Dados \\(\\to\\) Informação \\(\\to\\) Conhecimento \\(\\to\\) Sabedoria\n\nFonte: The Application of Visual Analytics to Financial Stability Monitoring"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#conhecimento-é-poder",
    "href": "1-introducao/1-introducao-ad.html#conhecimento-é-poder",
    "title": "Análise de dados",
    "section": "Conhecimento é poder!",
    "text": "Conhecimento é poder!"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#quem-tem-interesse",
    "href": "1-introducao/1-introducao-ad.html#quem-tem-interesse",
    "title": "Análise de dados",
    "section": "Quem tem interesse?",
    "text": "Quem tem interesse?\n\nEmpresas querem insights para melhorar seus negócios\nCidadãos querem mais transparência de dados e informação\nGovernos querem mecanismos para melhorar fiscalização"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#o-que-é-análise-e-ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#o-que-é-análise-e-ciência-de-dados",
    "title": "Análise de dados",
    "section": "O que é análise e ciência de dados?",
    "text": "O que é análise e ciência de dados?\n\nComo toda área nova, não há definições muito claras\nAlgumas definições relacionadas da Gartner:\n\nBusiness Inteligence (BI): Aplicações, ferramentas e melhores práticas que permitem o acesso e a análise de informações para melhorar e otimizar decisões e desempenho.\nAnalytics: Processo de analizar informações de um domínio particular. Ou a aplicação de BI para uma área específica.\nBig data: Grande volume, velocidade e/ou variedade de dados que exigem processamento eficiente e inovador de informações permitindo insights, decisões e automação de processos.\nCientista de dados: Extrai insights de dados. Requer habilidades analíticas para detectar padrões."
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#ciência-de-dados",
    "title": "Análise de dados",
    "section": "Ciência de dados",
    "text": "Ciência de dados\n\n\n\nIncorpora elementos de:\n\nExploratory Data Analysis (EDA) e Visualização de dados;\nMachine Learning e Estatística;\nComputação de Alto Desempenho\n\nHabilidades necessárias:\n\nCiência da Computação\nMatemática e Estatística\nExpertise nos domínios da aplicação\n\n\n\n\n\n\nFonte: Steven Skiena - Lecture 1: Introduction to Data Science"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#por-que-ciência-de-dados-agora",
    "href": "1-introducao/1-introducao-ad.html#por-que-ciência-de-dados-agora",
    "title": "Análise de dados",
    "section": "Por que ciência de dados agora?",
    "text": "Por que ciência de dados agora?\n\n\nNovas tecnologias para processar dados em larga escala\n\nRedes sociais, IoT, Cloud Computing, Big Data, Machine Learning\n\nSucesso de análise de dados em empresas serviu de modelo\n\nGoogle, Facebook, Amazon, Microsoft"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#apreciando-dados",
    "href": "1-introducao/1-introducao-ad.html#apreciando-dados",
    "title": "Análise de dados",
    "section": "Apreciando dados",
    "text": "Apreciando dados\n\nCientistas da computação geralmente não apreciam dados\n\nSó é algo que eles carregam nos programas\nGeralmente usam dados aleatórios para testar programas\nConjuntos de dados interessantes são recursos raros, que requerem trabalho duro e imaginação para obtê-los"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#section",
    "href": "1-introducao/1-introducao-ad.html#section",
    "title": "Análise de dados",
    "section": "",
    "text": "Cientista real\n\n\nSe esforça para entender a bagunça do mundo real\nNada é completamente verdadeiro ou falso\nDirecionados a dados\nObsessão por descobrir\nUtiliza dados com erros\n\n\n\nCientista da computação\n\n\nConstroe seu próprio mundo virtual organizado\nTudo é completamente verdadeiro ou falso\nDirecionado a algoritmos\nObsessão por inventar\nUtiliza dados corretos\n\n\n\n\n\nCientistas de dados devem pensar como cientistas reais!"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#ciência-tradicional-x-ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#ciência-tradicional-x-ciência-de-dados",
    "title": "Análise de dados",
    "section": "Ciência tradicional x ciência de dados",
    "text": "Ciência tradicional x ciência de dados\n\nCiência tradicional: formulação de hipóteses e obtenção de dados específicos para confirmá-las ou negá-las.\nCiência de dados: geração de dados em larga escala para realizar novas descobertas ao analisá-los.\nDuas formas importantes de pensar:\n\nDado um problema, quais dados ajudarão a resolvê-lo?\nDado um conjunto de dados, que problemas interessantes se aplicarão a ele?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#genialidade-x-sabedoria",
    "href": "1-introducao/1-introducao-ad.html#genialidade-x-sabedoria",
    "title": "Análise de dados",
    "section": "Genialidade x Sabedoria",
    "text": "Genialidade x Sabedoria\n\nDesenvolvedores são contratados para produzir código\nCientistas de dados são contratados para produzir insights\nGenialidade é saber encontrar a resposta correta\nSabedoria é saber evitar as respostas erradas!\nA sabedoria vem de:\n\nExperiência, conhecimento geral, ouvir os outros\nHumildade: observar quanto, como e porque você errou\n\n\n\nCiência de dados se beneficia mais de sábios que de gênios"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#desenvolvendo-a-curiosidade",
    "href": "1-introducao/1-introducao-ad.html#desenvolvendo-a-curiosidade",
    "title": "Análise de dados",
    "section": "Desenvolvendo a curiosidade",
    "text": "Desenvolvendo a curiosidade\n\nO bom cientista de dados desenvolve curiosidade sobre o domínio / aplicação que ele está trabalhando\nConversa com pessoas envolvidas nos dados que trabalha\nAcompanha notícias para ter uma visão ampla do mundo\nEles são encorajados a perguntar:\n\nQue coisas interessantes você consegue aprender de um certo conjunto de dados?\nQue coisas você realmente quer saber?\nQue conjunto de dados pode levar você a isso?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-dados-de-filmes-e-séries",
    "href": "1-introducao/1-introducao-ad.html#imdb-dados-de-filmes-e-séries",
    "title": "Análise de dados",
    "section": "IMDb: dados de filmes e séries",
    "text": "IMDb: dados de filmes e séries"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-dados-de-atores",
    "href": "1-introducao/1-introducao-ad.html#imdb-dados-de-atores",
    "title": "Análise de dados",
    "section": "IMDb: dados de atores",
    "text": "IMDb: dados de atores"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-perguntas-12",
    "href": "1-introducao/1-introducao-ad.html#imdb-perguntas-12",
    "title": "Análise de dados",
    "section": "IMDb: Perguntas? [1/2]",
    "text": "IMDb: Perguntas? [1/2]\n\nQuais atores atuaram em mais filmes? Nos melhores filmes? Ganharam mais dinheiro? Com carreiras mais longas?\nQuais os filmes com melhores/piores avaliações? Por ano? Por gênero? Mais caros? Com elencos mais poderosos?\nFilmes com maior faturamento recebem notas maiores e mais prêmios? É possível prever a nota e o faturamento?\nComo os filmes de Hollywood se comparam a filmes indianos em: avaliação, orçamento, rendimento? Filmes americanos são mais bem avaliados do que estrangeiros?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-perguntas-22",
    "href": "1-introducao/1-introducao-ad.html#imdb-perguntas-22",
    "title": "Análise de dados",
    "section": "IMDb: Perguntas? [2/2]",
    "text": "IMDb: Perguntas? [2/2]\n\nComo é a rede social da participação de atores em filmes?\n\nExemplo: grafo que indica graus a partir de Kevin Bacon\n\nQual é a distribuição de idade de atores e atrizes em filmes? Atrizes tendem a ser mais jovens que atores?\nQuais gêneros de filmes recebem as melhores avaliações? Quais gêneros são mais caros? Quais faturam mais?\nQual a probabilidade de uma pessoa gostar de um filme? (Exemplo: recomendações do Netflix)"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#referências",
    "href": "1-introducao/1-introducao-ad.html#referências",
    "title": "Análise de dados",
    "section": "Referências",
    "text": "Referências\n\nSkiena S.S. (2017) What is Data Science?. In: The Data Science Design Manual. Texts in Computer Science. Springer.\n\nCSE 519: Data Science - Steven Skiena - Lecture 1: Introduction to Data Science\n\n\n\n\nProf. Marcus Carvalho @ DCX / CCAE / UFPB"
  },
  {
    "objectID": "1-introducao/2-intro-python-jupyter.html",
    "href": "1-introducao/2-intro-python-jupyter.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Nós iremos usar a linguagem Python para demonstrações nas aulas e atividades práticas do curso. Espera-se que você já tenha algum contato com Python em disciplinas anteriores. Além disso, nós usaremos o Jupyter Notebook para criação de notebooks que servirão para fazer as atividades práticas e os relatórios de análise de dados.\nPara se familiarizar com as ferramentas e montar o ambiente de desenvolvimento necessário para o curso, nessa atividade vocês irão instalar o Python e o Jupyter Notebook e seguir um passo a passo de um Notebook para revisar os conceitos básicos dessas ferramentas. Além de conseguir rodar um notebook na sua máquina local, você também deve ser capaz de experimentar a execução de notebooks Jupyter em ambientes de execução na nuvem, como através do GitHub Codespaces e do Google Colab.\nNesta atividade, você deve seguir o passo a passo dos capítulos 2 - Python Language Basics, IPython, and Jupyter Notebooks e 3 - Built-In Data Structures, Functions, and Files do livro Python for Data Science, seguindo suas instruções através de notebooks dos capítulos.\nNo repositório do livro no GitHub o autor disponibiliza o Notebook reference a estes capítulos nos arquivos ch02.ipynb e ch03.ipynb. Nesta atividade, você deve ser capaz de abrir cada Notebook em um ambiente de execução e executar o seu código.\nAntes de começar, você deve:\n\nInstalar o Python\nInstalar o Jupyter Notebook\nInstalar o git\n\n\n\nVamos iniciar com a execução do Notebook do capítulo 2 (ch02.ipynb)\n\n\nPara rodar localmente, você deve baixar o arquivo ch02.ipynb para a sua máquina. Para isso, você pode fazer um clone do repositório que possui todos os notebooks do livro, rodando em um terminal:\ngit clone https://github.com/wesm/pydata-book \nEm seguida, entre no diretório do repositório e mude para a branch da 3a edição do livro, que iremos usar nas atividades, rodando:\ncd pydata-book\ngit checkout 3rd-edition\n\n\n\n\n\n\nDica\n\n\n\nSe não quiser baixar todo o repositório do livro, você pode fazer o download apenas do arquivo específico no repositório.\n\n\n\n\n\nNo diretório onde está o arquivo do notebook (pydata-book), inicie o Jupyter rodando no terminal:\njupyter notebook\nEste comando deve abrir um browser com o Jupyter Notebook em execução, como na imagem abaixo:\n\nLocalize o nome do arquivo do notebook ch02.ipynb e clique em seu nome para abrir.\nSe deu tudo certo, você deve ver uma tela como a de baixo:\n\nO notebook combina blocos de texto (Markdown) com blocos de código. Você deve fazer a leitura do notebook e ser capaz de executar todas as células que contêm código. Para executar uma célula de código, clique na célula para selecioná-la e clique no botão Run do menu acima. O código é apresentado no bloco In e a saída gerada pela execução do código é apresentada no bloco Out, conforme imagem abaixo.\n\nVocê deve seguir a execução dos blocos na sequência, porque pode existir uma dependência do código de baixo com o de cima. Se quiser rodar todas as células na sequência, você pode ir no menu Cell -> Run All. Verique se houve algum erro na execução de alguma célula, verificando as saídas que cada uma gerou.\nVocê também pode editar o conteúdo do notebook, alterando o código ou o texto dos blocos, ou adicionando novas células.\nInsira uma nova célula de código no final do notebook com código Python que imprime essa mensagem:\nprint(\"Agora eu sei editar e executar um Jupyter Notebook!\")\nVocê pode inserir novas células escolhendo na barra de menu o tipo de célula (Code para código ou Markdown para texto) e clicando no botão +. Você também pode fazer isso clicando em Insert no menu superior.\n\n\n\nOs notebooks jupyter também podem ser executados diretamente de alguma IDE que dê suporte para ele, como VS Code (com a extensão Python) e PyCharm. Para isso vocês devem ter instalado o Python e o Jupyter Notebook anteriormente.\nTeste executar o notebook em sua IDE favorita (durante a disciplina usarei o VS Code para demonstrações).\n\n\n\n\nVocê também pode rodar o notebook em algum serviço da nuvem gratuito como o Google Colab. Para isso, acesse em seu browser o endereço https://colab.research.google.com.\n\n\n\n\n\n\nAtenção\n\n\n\nO ideal é estar logado com a sua conta Google do domínio @dcx.ufpb.br para usar o Google Notebook.\n\n\nAo abrir o Colab, você pode fazer o upload do arquivo notebook (.ipynb) que deseja executar. Uma forma ainda mais fácil é criar um notebook usando a opção GitHub, inserindo o link do repositório do livro https://github.com/wesm/pydata-book, escolhendo a ramificação (branch) 3rd-edition e clicando no nome do arquivo ch02.ipynb para abrí-lo, como na imagem abaixo:\n\nCom isso, você terá um ambiente de execução do notebook que pode ser editado e executado de forma similar ao ambiente Jupyter, mas que irá rodar na nuvem da Google e poderá ser compartilhado facilmente com outras pessoas. A tela de edição do notebook no Colab é mostrada abaixo:\n\n\n\n\nO GitHub também criou um ambiente de desenvolvimento e execução de código na própria plataforma, chamada GitHub Codespaces, que abre no browser uma IDE similar ao VS Code onde você também consegue executar notebooks Jupyter.\nPara criar um Codespace para o notebook da atividade, entre na página do repositório no GitHub, escolha a branch correta (3rd-edition), clique no botão Code e em seguida em Create codespace on 3rd-edition, conforme a imagem abaixo.\n\n\n\n\n\n\n\nDica\n\n\n\nVocê também pode criar um Codespace apertando a tecla . do teclado na página do repositório e da branch que você deseja.\n\n\n\n\n\nPara fazer outro teste dos passos feitos anteriormente e também fazer uma revisão de estruturas de dados, funções e arquivos em Python, você deve seguir o passo a passo do notebook do capítulo 3, lendo e executando os blocos do notebook.\nEscolha o ambiente de execução mais adequado para você (Jupyter, IDE ou Colab) e faça novamente os passos anteriores, agora com o arquivo ch03.ipynb do repositório.\n\n\n\n\nMcKinney, Wes. Python for Data Analysis(3rd Edition). O’Reilly Media, 2022."
  },
  {
    "objectID": "2-eda/1-intro-eda.html#o-que-é-eda",
    "href": "2-eda/1-intro-eda.html#o-que-é-eda",
    "title": "Análise de dados",
    "section": "O que é EDA?",
    "text": "O que é EDA?\n\nSumarização e visualização de dados para analisar suas características principais\nCiclo iterativo:\n\nFaça perguntas sobre os dados.\nProcure respostas visualizando, transformando e modelando os dados.\nUse o que aprendeu para refinar perguntas e/ou fazer novas perguntas.\n\nInicialmente, investigue qualquer ideia que surgir\n\nAlgumas darão certo, outras não."
  },
  {
    "objectID": "2-eda/1-intro-eda.html#section",
    "href": "2-eda/1-intro-eda.html#section",
    "title": "Análise de dados",
    "section": "",
    "text": "“Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#fazendo-perguntas",
    "href": "2-eda/1-intro-eda.html#fazendo-perguntas",
    "title": "Análise de dados",
    "section": "Fazendo perguntas",
    "text": "Fazendo perguntas\n\nSeu objetivo na EDA é desenvolver um entendimento dos dados\n\nA forma mais fácil é fazendo perguntas para guiar sua investigação\nFoca sua atenção em partes específicas dos dados\nAjuda a decidir que gráficos, modelos ou transformações fazer\n\nÉ um processo criativo\n\nProduzir grande quantidade de perguntas para obter qualidade\nComo fazer perguntas reveladoras sem conhecer os dados?\n\nCada pergunta expõe um novo aspecto dos dados\n\nAumenta a chance de novas descobertas\nLeva a insights interessantes deixando as perguntas levarem a outras"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#tipos-de-perguntas",
    "href": "2-eda/1-intro-eda.html#tipos-de-perguntas",
    "title": "Análise de dados",
    "section": "Tipos de perguntas",
    "text": "Tipos de perguntas\n\nDois tipos muito úteis para novas descobertas:\n\nQue tipo de variação ocorre em cada variável?\nQue tipo de covariação ocorre entre as minhas variáveis?\n\nAlgumas definições:\n\nVariável: quantidade, qualidade ou propriedade que se pode medir\nValor: estado de uma variável quando você a mede (pode mudar)\nObservação: conjunto de medições feitas em condições similares"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#o-que-é-variância-e-por-que-analisá-la",
    "href": "2-eda/1-intro-eda.html#o-que-é-variância-e-por-que-analisá-la",
    "title": "Análise de dados",
    "section": "O que é variância e por que analisá-la?",
    "text": "O que é variância e por que analisá-la?\n\nTendência de variável mudar seu valor entre uma medição e outra\nCada variável tem seu próprio padrão de variação\n\nPode revelar informações interessantes\n\nVisualizar a distribuição dos dados ajuda a entender padrões\nComo visualizar distribuições?\n\nDepende se dados são categóricos ou contínuos"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-categóricos",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-categóricos",
    "title": "Análise de dados",
    "section": "Visualizando dados categóricos",
    "text": "Visualizando dados categóricos\n\nVariável que só pode assumir pequeno conjunto de valores\nExaminando a distribuição com gráfico de barras:\n\n\n\n\ndfw\n\n\n\n\n\n  \n    \n      \n      Count\n    \n    \n      Cause\n      \n    \n  \n  \n    \n      Carrier\n      64263.16\n    \n    \n      ATC\n      84856.50\n    \n    \n      Weather\n      11235.42\n    \n    \n      Security\n      343.15\n    \n    \n      Inbound\n      118427.82\n    \n  \n\n\n\n\n\n\nax = dfw.plot.bar(legend=False, figsize=(5, 4))"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos",
    "text": "Visualizando dados contínuos\n\nVariável com valor em um conjunto infinito de valores possíveis\nHistograma ou computando faixas manualmente\n\n\n\n\nbinPop = pd.cut(population, 10)\nbinPop.value_counts()\n\n(0.527, 4.233]      24\n(4.233, 7.902]      14\n(7.902, 11.571]      6\n(11.571, 15.24]      2\n(15.24, 18.909]      1\n(18.909, 22.578]     1\n(22.578, 26.247]     1\n(33.585, 37.254]     1\n(26.247, 29.916]     0\n(29.916, 33.585]     0\nName: Population, dtype: int64\n\n\n\n\nax = population.plot.hist(figsize=(5, 4))\nax = ax.set_xlabel('Population (millions)')"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-histograma",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-histograma",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos: Histograma",
    "text": "Visualizando dados contínuos: Histograma\n\nO parâmetro bins define a quantidade de intervalos\n\nExemplo para estados com menos de 10 milhões de habitantes\n\n\n\nax = population[population < 10].plot.hist(bins=5, figsize=(5, 4))"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-density-plot",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-density-plot",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos: density plot",
    "text": "Visualizando dados contínuos: density plot\n\nSimilar ao histograma, mas com linha contínua suavizada\n\nExemplo para taxas de homicídio nos Estados Unidos\n\n\n\nax = murder_rate.plot.hist(density=True, xlim=[0,12], bins=range(1,12))\nax = murder_rate.plot.density(ax=ax)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-percentis",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-percentis",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos: percentis",
    "text": "Visualizando dados contínuos: percentis\n\nFaz recortes dos dados ordenados em posições específicas\nPode ser usado para examinar distribuição dos dados\nÉ muito comum reportar os quartis (25, 50 e 75 percentil)\n\n50 percentil é a mediana, divide os dados ao meio\n\nTambém é usado para analisar valores na cauda (ex: 99 percentil)\nExemplo: percentis para taxa de homicídios nos Estados Unidos\n\n\nmurder_rate.quantile([0.05, 0.25, 0.5, 0.75, 0.95])\n\n0.05    1.600\n0.25    2.425\n0.50    4.000\n0.75    5.550\n0.95    6.510\nName: Murder.Rate, dtype: float64"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-boxplot",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-boxplot",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos: boxplot",
    "text": "Visualizando dados contínuos: boxplot\n\nMostra visualmente estatísticas populares de uma distribuição"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-boxplot-1",
    "href": "2-eda/1-intro-eda.html#visualizando-dados-contínuos-boxplot-1",
    "title": "Análise de dados",
    "section": "Visualizando dados contínuos: boxplot",
    "text": "Visualizando dados contínuos: boxplot\n\n\n\nExemplo: populações dos EUA\n\nObservamos que:\n\nA mediana é aproximadamente 5 milhões de habitantes\nMetade dos estados tem entre 2 e 7 milhões de habitantes\nPopulações acima de 13 milhões são consideradas incomuns (outliers)\n\n\n\n\n\nax = population.plot.box()"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#outliers",
    "href": "2-eda/1-intro-eda.html#outliers",
    "title": "Análise de dados",
    "section": "Outliers",
    "text": "Outliers\n\nOutliers são valores muito distantes dos outros\n\nPodem ser dados com erros, mas também podem ser válidos\n\nSe for erro podem ser excluídos, mas com boa justificativa\n\nRequer investigação mais detalhada para entender o caso\nExemplo das populações outliers e impacto nas estatísticas:\n\n\n\n\n\nstate[state['Population'] > 13]\n\n\n\n\n\n  \n    \n      \n      State\n      Population\n      Murder.Rate\n      Abbreviation\n    \n  \n  \n    \n      4\n      California\n      37.253956\n      4.4\n      CA\n    \n    \n      8\n      Florida\n      18.801310\n      5.8\n      FL\n    \n    \n      31\n      New York\n      19.378102\n      3.1\n      NY\n    \n    \n      42\n      Texas\n      25.145561\n      4.4\n      TX\n    \n  \n\n\n\n\n\n\nstate.Population.agg([\"mean\", \"median\"])\n\nmean      6.162876\nmedian    4.436369\nName: Population, dtype: float64"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#o-que-é-covariância-e-por-que-analisá-la",
    "href": "2-eda/1-intro-eda.html#o-que-é-covariância-e-por-que-analisá-la",
    "title": "Análise de dados",
    "section": "O que é covariância e por que analisá-la?",
    "text": "O que é covariância e por que analisá-la?\n\nCovariância descreve o comportamento entre variáveis.\n\nTendência de 2 ou mais variáveis variarem juntas, de forma relacionada.\n\nÚtil para encontrar padrões de relacionamento entre variáveis\n\nE criar modelos que estimam valores com base nessas relações\nEx: estimar votos de candidatos com base nos gastos de campanha\n\nA melhor forma de identificar covariância é visualizar o relacionamento entre variáveis\n\nNovamente, isto depende dos tipos das variáveis"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-categóricas",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-categóricas",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis categóricas",
    "text": "Covariância: duas variáveis categóricas\n\nVamos analisar uma base de dados de empréstimos\n\n\n\n\nloans\n\n\n\n\n\n  \n    \n      \n      status\n      grade\n    \n  \n  \n    \n      0\n      Fully Paid\n      B\n    \n    \n      1\n      Charged Off\n      C\n    \n    \n      2\n      Fully Paid\n      C\n    \n    \n      3\n      Fully Paid\n      C\n    \n    \n      4\n      Current\n      B\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      450956\n      Current\n      D\n    \n    \n      450957\n      Current\n      D\n    \n    \n      450958\n      Current\n      D\n    \n    \n      450959\n      Current\n      D\n    \n    \n      450960\n      Fully Paid\n      A\n    \n  \n\n450961 rows × 2 columns\n\n\n\n\n\nO nível do empréstimo (grade) é uma variável categórica ordinal\n\nHá uma ordem do nível melhor (A) para o pior (G)\n\nO resultado (status) é uma variável não ordinal\n\nNão há ordem pré-definida dos seus valores"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-categóricas-1",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-categóricas-1",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis categóricas",
    "text": "Covariância: duas variáveis categóricas\n\nPodemos contar as observações para cada combinação\n\nVisualizando com tabela pivot e mapa de calor (heatmap)\n\n\n\n\n\nloans.pivot_table(index='grade', columns='status',\n                  aggfunc=lambda x: len(x))\n\n\n\n\n\n  \n    \n      status\n      Charged Off\n      Current\n      Fully Paid\n      Late\n    \n    \n      grade\n      \n      \n      \n      \n    \n  \n  \n    \n      A\n      1562\n      50051\n      20408\n      469\n    \n    \n      B\n      5302\n      93852\n      31160\n      2056\n    \n    \n      C\n      6023\n      88928\n      23147\n      2777\n    \n    \n      D\n      5007\n      53281\n      13681\n      2308\n    \n    \n      E\n      2842\n      24639\n      5949\n      1374\n    \n    \n      F\n      1526\n      8444\n      2328\n      606\n    \n    \n      G\n      409\n      1990\n      643\n      199\n    \n  \n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(5, 4))\nax = sns.heatmap(loans_pivot, annot=True, fmt=\"d\")"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua",
    "href": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua",
    "title": "Análise de dados",
    "section": "Covariância: uma categórica e uma contínua",
    "text": "Covariância: uma categórica e uma contínua\n\nCovariância de 2 variáveis da base de dados de voôs cancelados\n\nairline (categórica não ordinal): nome da empresa aérea\npct_carrier_delay (contínua): % de atrasos causados pela empresa\n\n\n\n\nairline_stats\n\n\n\n\n\n  \n    \n      \n      airline\n      pct_carrier_delay\n      pct_weather_delay\n      pct_atc_delay\n    \n  \n  \n    \n      0\n      American\n      8.153226\n      0.762097\n      1.971774\n    \n    \n      1\n      American\n      5.959924\n      1.585878\n      3.706107\n    \n    \n      2\n      American\n      7.157270\n      2.026706\n      2.706231\n    \n    \n      3\n      American\n      12.100000\n      0.000000\n      11.033333\n    \n    \n      4\n      American\n      7.333333\n      1.774194\n      3.365591\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      33463\n      Southwest\n      6.186422\n      1.651940\n      8.798491\n    \n    \n      33464\n      Southwest\n      9.522167\n      0.261084\n      3.591133\n    \n    \n      33465\n      Southwest\n      9.164179\n      0.343284\n      2.664179\n    \n    \n      33466\n      Southwest\n      5.152293\n      0.122817\n      1.964520\n    \n    \n      33467\n      Southwest\n      3.964393\n      0.019449\n      1.700479\n    \n  \n\n33468 rows × 4 columns"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua-1",
    "href": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua-1",
    "title": "Análise de dados",
    "section": "Covariância: uma categórica e uma contínua",
    "text": "Covariância: uma categórica e uma contínua\n\nBoxplot e density plot da contínua agrupado pela categórica\n\n\n\n\nax = airline_stats.boxplot(by='airline',\n  column='pct_carrier_delay', figsize=(6, 5))\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax = sns.kdeplot(data=airline_stats,\n  x=\"pct_carrier_delay\", hue=\"airline\")"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua-2",
    "href": "2-eda/1-intro-eda.html#covariância-uma-categórica-e-uma-contínua-2",
    "title": "Análise de dados",
    "section": "Covariância: uma categórica e uma contínua",
    "text": "Covariância: uma categórica e uma contínua\n\nviolin plot é outra alternativa ao boxplot\n\n\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax = sns.violinplot(data=airline_stats,\n  x='airline', y='pct_carrier_delay', ax=ax, inner='quartile')\n\n\n\n\n\n\nMostra a densidade da contínua para cada grupo da categóricas\nÉ mais fácil observar a concentração dos dados.\nNota-se:\n\nUma concentração mais perto de 0% para a Alaska\nDelta e United com mais valores extremos (outliers)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis contínuas",
    "text": "Covariância: duas variáveis contínuas\n\n\n\nVamos analisar a variação diária da cotação de empresas de telecomunicação na bolsa de valores\nSe quisermos comparar a covariância da cotação de duas empresas?\n\nTeremos duas variáveis contínuas\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      T\n      CTL\n      FTR\n      VZ\n      LVLT\n    \n  \n  \n    \n      2012-07-02\n      0.422496\n      0.140847\n      0.070879\n      0.554180\n      -0.519998\n    \n    \n      2012-07-03\n      -0.177448\n      0.066280\n      0.070879\n      -0.025976\n      -0.049999\n    \n    \n      2012-07-05\n      -0.160548\n      -0.132563\n      0.055128\n      -0.051956\n      -0.180000\n    \n    \n      2012-07-06\n      0.342205\n      0.132563\n      0.007875\n      0.140106\n      -0.359999\n    \n    \n      2012-07-09\n      0.136883\n      0.124279\n      -0.023626\n      0.253943\n      0.180000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2015-06-25\n      0.049342\n      -1.600000\n      -0.040000\n      -0.187790\n      -0.330002\n    \n    \n      2015-06-26\n      -0.256586\n      0.039999\n      -0.070000\n      0.029650\n      -0.739998\n    \n    \n      2015-06-29\n      -0.098685\n      -0.559999\n      -0.060000\n      -0.504063\n      -1.360000\n    \n    \n      2015-06-30\n      -0.503298\n      -0.420000\n      -0.070000\n      -0.523829\n      0.199997\n    \n    \n      2015-07-01\n      -0.019737\n      0.080000\n      -0.050000\n      0.355811\n      0.139999\n    \n  \n\n754 rows × 5 columns"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-1",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-1",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis contínuas",
    "text": "Covariância: duas variáveis contínuas\n\nScatterplot comparando cotação diária da Verizon (V) x AT&T (T)\n\nCom transparência (alpha) destacamos a concentração dos pontos\n\n\n\n\n\nax = telecom.plot.scatter(x='T', y='VZ',\n       figsize=(6, 5))\n\n\n\n\n\n\nax = telecom.plot.scatter(x='T', y='VZ',\n       alpha=0.4, linewidth=0, figsize=(6, 5))"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-2",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-2",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis contínuas",
    "text": "Covariância: duas variáveis contínuas\n\nOutras alternativas: hexbin e jointplot (com kind='hex')\n\n\n\n\nax = telecom.plot.hexbin(x='T', y='VZ', gridsize=30, sharex=False, figsize=(6, 5))\n\n\n\n\n\n\nax = sns.jointplot(x='T', y='VZ', kind=\"hex\", height=5, data=telecom)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-3",
    "href": "2-eda/1-intro-eda.html#covariância-duas-variáveis-contínuas-3",
    "title": "Análise de dados",
    "section": "Covariância: duas variáveis contínuas",
    "text": "Covariância: duas variáveis contínuas\n\nAnalisando tamanho x valor de casas em uma região dos EUA\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      TaxAssessedValue\n      SqFtTotLiving\n      ZipCode\n    \n  \n  \n    \n      3\n      361000.0\n      2000\n      98108\n    \n    \n      4\n      459000.0\n      3150\n      98108\n    \n    \n      10\n      202000.0\n      830\n      98108\n    \n    \n      11\n      210000.0\n      1130\n      98108\n    \n    \n      12\n      193000.0\n      1560\n      98108\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      498049\n      346000.0\n      1430\n      98105\n    \n    \n      498050\n      463000.0\n      1610\n      98105\n    \n    \n      498051\n      553000.0\n      1580\n      98105\n    \n    \n      498052\n      571000.0\n      1840\n      98105\n    \n    \n      498053\n      694000.0\n      2420\n      98105\n    \n  \n\n19690 rows × 3 columns\n\n\n\n\n\nax = sns.jointplot(data=kc_tax0, x='SqFtTotLiving', y='TaxAssessedValue', kind=\"hex\", height=5)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#covariância-duas-contínuas-e-uma-categórica",
    "href": "2-eda/1-intro-eda.html#covariância-duas-contínuas-e-uma-categórica",
    "title": "Análise de dados",
    "section": "Covariância: duas contínuas e uma categórica",
    "text": "Covariância: duas contínuas e uma categórica\n\n\n\nA localização (ZipCode) da casa também influencia o preço?\nUsamos facets para quebrar em um subplot por categoria\nNota-se a influência tanto da localização quanto do tamanho no valor da casa\n\n\n\n\nCode\ndef hexbin(x, y, color, **kwargs):\n    cmap = sns.light_palette(color, as_cmap=True)\n    plt.hexbin(x, y, gridsize=25, cmap=cmap, **kwargs)\n\ng = sns.FacetGrid(kc_tax_zip, col='ZipCode', col_wrap=2)\nax = g.map(hexbin, 'SqFtTotLiving', 'TaxAssessedValue', \n      extent=[0, 3500, 0, 700000])\n\ng.set_axis_labels('Finished Square Feet', 'Tax Assessed Value')\ng.set_titles('Zip code {col_name:.0f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n::::"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes",
    "text": "Exemplo EDA - diamantes\n\nDados de diamantes com variáveis: quilates (caret), qualidade do corte (cut), cor (color), claridade (clarity), preço (price), etc.\n\n\n\n\n\n\n\n\n  \n    \n      \n      carat\n      cut\n      color\n      clarity\n      depth\n      table\n      price\n      x\n      y\n      z\n    \n  \n  \n    \n      0\n      0.23\n      Ideal\n      E\n      SI2\n      61.5\n      55.0\n      326\n      3.95\n      3.98\n      2.43\n    \n    \n      1\n      0.21\n      Premium\n      E\n      SI1\n      59.8\n      61.0\n      326\n      3.89\n      3.84\n      2.31\n    \n    \n      2\n      0.23\n      Good\n      E\n      VS1\n      56.9\n      65.0\n      327\n      4.05\n      4.07\n      2.31\n    \n    \n      3\n      0.29\n      Premium\n      I\n      VS2\n      62.4\n      58.0\n      334\n      4.20\n      4.23\n      2.63\n    \n    \n      4\n      0.31\n      Good\n      J\n      SI2\n      63.3\n      58.0\n      335\n      4.34\n      4.35\n      2.75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      53935\n      0.72\n      Ideal\n      D\n      SI1\n      60.8\n      57.0\n      2757\n      5.75\n      5.76\n      3.50\n    \n    \n      53936\n      0.72\n      Good\n      D\n      SI1\n      63.1\n      55.0\n      2757\n      5.69\n      5.75\n      3.61\n    \n    \n      53937\n      0.70\n      Very Good\n      D\n      SI1\n      62.8\n      60.0\n      2757\n      5.66\n      5.68\n      3.56\n    \n    \n      53938\n      0.86\n      Premium\n      H\n      SI2\n      61.0\n      58.0\n      2757\n      6.15\n      6.12\n      3.74\n    \n    \n      53939\n      0.75\n      Ideal\n      D\n      SI2\n      62.2\n      55.0\n      2757\n      5.83\n      5.87\n      3.64\n    \n  \n\n53940 rows × 10 columns"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-variância",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-variância",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: Variância",
    "text": "Exemplo EDA - diamantes: Variância\n\n\n\nCorte (categórica ordinal)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax = sns.countplot(data=diamond, x='cut',\n  order=['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'])\n\n\n\n\n\n\nQuilates (contínua)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax = sns.histplot(data=diamond, x=\"carat\",\n                  binwidth=0.2)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: covariância",
    "text": "Exemplo EDA - diamantes: covariância\n\nRelação de preço e corte dos diamantes com density e box plot\n\nPor que melhor corte (Ideal) é mais barato?\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6, 4))\nax = sns.kdeplot(x=\"price\", hue=\"cut\", data=diamond)\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6, 4))\nax = sns.boxplot(x='price', y='cut', data=diamond)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância-1",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância-1",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: covariância",
    "text": "Exemplo EDA - diamantes: covariância\n\nRelação de corte e cor (duas variáveis categóricas)\n\n\ncut_color = diamond[['cut', 'color']].pivot_table(index='cut', columns='color', aggfunc=len)\nfig, ax = plt.subplots(figsize=(9, 5))\nax = sns.heatmap(cut_color, annot=True, fmt=\"d\", cmap=\"YlGnBu\")"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância-2",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-covariância-2",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: covariância",
    "text": "Exemplo EDA - diamantes: covariância\n\nRelação de preço e quilates (duas variáveis contínuas)\n\n\nax = sns.jointplot(x=\"carat\", y=\"price\", linewidth=0, alpha=0.01, height=5, data=diamond)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-2-contínuas-e-1-categórica",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-2-contínuas-e-1-categórica",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: 2 contínuas e 1 categórica",
    "text": "Exemplo EDA - diamantes: 2 contínuas e 1 categórica\n\ng = sns.FacetGrid(diamond, col=\"cut\", col_wrap=3)\nax = g.map_dataframe(sns.scatterplot, x=\"carat\", y=\"price\", alpha=0.1, linewidth=0)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-2-contínuas-e-2-categóricas",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---diamantes-2-contínuas-e-2-categóricas",
    "title": "Análise de dados",
    "section": "Exemplo EDA - diamantes: 2 contínuas e 2 categóricas",
    "text": "Exemplo EDA - diamantes: 2 contínuas e 2 categóricas\n\n\n\nCode\ndiamond[\"price (k$)\"] = diamond[\"price\"] / 1000\ng = sns.FacetGrid(diamond, row=\"cut\", col=\"clarity\", margin_titles=True, height=1.3)\nax = g.map_dataframe(sns.scatterplot, x=\"carat\", y=\"price (k$)\", alpha=0.3, linewidth=0)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#padrões-nos-dados",
    "href": "2-eda/1-intro-eda.html#padrões-nos-dados",
    "title": "Análise de dados",
    "section": "Padrões nos dados",
    "text": "Padrões nos dados\n\nSe encontrar padrões, pergunte-se:\n\nEste padrão acontece por coincidência?\nComo você descreve o relaciomento implicado pelo padrão?\nQuão forte é o relacionado implicado pelo padrão?\nQue outras variáveis afetam este relacionamento?\nO relacionamento muda se você olhar subgrupos individuais dos dados?"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---vulcão",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---vulcão",
    "title": "Análise de dados",
    "section": "Exemplo EDA - vulcão",
    "text": "Exemplo EDA - vulcão\n\nDados de erupções do vulcão Old Faithful Geyser\n\neruptions: duração da erupção em segundos\nwaiting: tempo entre a erupção atual e a seguinte\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      eruptions\n      waiting\n    \n  \n  \n    \n      0\n      3.600\n      79\n    \n    \n      1\n      1.800\n      54\n    \n    \n      2\n      3.333\n      74\n    \n    \n      3\n      2.283\n      62\n    \n    \n      4\n      4.533\n      85\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      267\n      4.117\n      81\n    \n    \n      268\n      2.150\n      46\n    \n    \n      269\n      4.417\n      90\n    \n    \n      270\n      1.817\n      46\n    \n    \n      271\n      4.467\n      74\n    \n  \n\n272 rows × 2 columns"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---vulcão-variância",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---vulcão-variância",
    "title": "Análise de dados",
    "section": "Exemplo EDA - vulcão: variância",
    "text": "Exemplo EDA - vulcão: variância\n\nAnalisando a variância de eruptions e waiting\n\n\n\n\nfig, ax = plt.subplots(figsize=(5, 4))\nax = sns.histplot(x='eruptions', data=faithful)\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(5, 4))\nax = sns.histplot(x='waiting', data=faithful)"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#exemplo-eda---vulcão-covariância",
    "href": "2-eda/1-intro-eda.html#exemplo-eda---vulcão-covariância",
    "title": "Análise de dados",
    "section": "Exemplo EDA - vulcão: covariância",
    "text": "Exemplo EDA - vulcão: covariância\n\n\n\nfig, ax = plt.subplots(figsize=(7, 6))\nax = sns.scatterplot(x='eruptions', y='waiting', data=faithful)\n\n\n\n\n\n\nTempos de espera mais longos após erupções mais longas\nVariância gera incerteza\nCovariância reduz incerteza\nUma variável pode ajudar a prever a outra"
  },
  {
    "objectID": "2-eda/1-intro-eda.html#referências",
    "href": "2-eda/1-intro-eda.html#referências",
    "title": "Análise de dados",
    "section": "Referências",
    "text": "Referências\n\nBruce, P. et al. Practical Statistics for Data Scientists. 2nd Edition. O’Reilly, 20220. Code and Datasets: https://github.com/gedeck/practical-statistics-for-data-scientists\nWickhan, H. R for Data Science. O’Reilly, 2017. Open Access: http://r4ds.had.co.nz\nGrus, Joel. Data Science do Zero. Editora Alta Books, 2021. Disponível em: Minha Biblioteca da UFPB."
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#probabilidade-vs.-estatística",
    "href": "2-eda/2-estatistica-descritiva.html#probabilidade-vs.-estatística",
    "title": "Análise de dados",
    "section": "Probabilidade vs. Estatística",
    "text": "Probabilidade vs. Estatística\n\nA probabilidade busca prever a chance de eventos futuros ocorrerem\n\nA estatística analisa a frequência de eventos passados\n\n\n\nA probabilidade é um ramo da matemática teórica sobre consequências de definições\nA estatística é matemática aplicada na busca de entender observações do mundo real"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#distribuições-de-variáveis-aleatórias",
    "href": "2-eda/2-estatistica-descritiva.html#distribuições-de-variáveis-aleatórias",
    "title": "Análise de dados",
    "section": "Distribuições de variáveis aleatórias",
    "text": "Distribuições de variáveis aleatórias\n\nVariáveis Aleatórias (VAs) são funções numéricas onde valores possuem probabilidades\nA função densidade de probabilidade (FDP) mostra VAs (como histogramas)"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#distribuições-de-variáveis-aleatórias-1",
    "href": "2-eda/2-estatistica-descritiva.html#distribuições-de-variáveis-aleatórias-1",
    "title": "Análise de dados",
    "section": "Distribuições de variáveis aleatórias",
    "text": "Distribuições de variáveis aleatórias\n\nFunção Densidade Acumulada (FDA) é o somatório da FDP\n\nFDA é a integral da FDP, enquanto a FDP é a derivada da FDA\n\n\n\\[C(X \\leq k) = \\sum_{x \\leq k} P(X = x)\\]"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#visualizando-distribuições-acumuladas",
    "href": "2-eda/2-estatistica-descritiva.html#visualizando-distribuições-acumuladas",
    "title": "Análise de dados",
    "section": "Visualizando distribuições acumuladas",
    "text": "Visualizando distribuições acumuladas\n\nAs vendas de iPhone estão bombando?"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#o-crescimento-é-mesmo-significativo",
    "href": "2-eda/2-estatistica-descritiva.html#o-crescimento-é-mesmo-significativo",
    "title": "Análise de dados",
    "section": "O crescimento é mesmo significativo?",
    "text": "O crescimento é mesmo significativo?\n\nFDAs podem dar uma visão errônea do crescimento\n\nA mudança incremental é a derivada da FDA, que é difícil de visualizar"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#estatística-descritiva-vs.-inferencial",
    "href": "2-eda/2-estatistica-descritiva.html#estatística-descritiva-vs.-inferencial",
    "title": "Análise de dados",
    "section": "Estatística descritiva vs. inferencial",
    "text": "Estatística descritiva vs. inferencial\n\nEstatística descritiva: captura propriedades e distribuição dos dados\n\nMedidas de tendência central descrevem o centro de sua distribuição\nMedidas de variabilidade ou dispersão descrevem o seu espalhamento\n\n\n\n\nEstatística inferencial: tomar decisões e achar relações nos dados\n\nUsa fundamentos e teorias da probabilidade\nPreocupa-se em modelar fenômenos aleatórios\nExemplo: as diferenças nos dados entre duas situações podem ser atribuídas a diferenças reais ou ao acaso?"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#estatística-descritiva",
    "href": "2-eda/2-estatistica-descritiva.html#estatística-descritiva",
    "title": "Análise de dados",
    "section": "Estatística descritiva",
    "text": "Estatística descritiva\nObjetivos:\n\nDar uma noção de como os dados estão distribuídos\nEntender melhor a natureza dos dados\nIdentificar pontos anormais (possíveis outliers)\nApresentação gráfica de aspectos importantes dos dados\nIdentificar relações entre variáveis"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medidas-de-centralidade-com-número-único",
    "href": "2-eda/2-estatistica-descritiva.html#medidas-de-centralidade-com-número-único",
    "title": "Análise de dados",
    "section": "Medidas de centralidade com número único",
    "text": "Medidas de centralidade com número único\n\nUm número que seja representativo da maior parte dos dados\nA princípio pode parecer trivial: é só calcular a média\n\nEm alguns casos ela pode não ser a melhor medida de valor central\n\n\n\n\nÍndices de tendência central (average) mais populares:\n\nMédia amostral\nMediana amostral\nModa amostral"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-média-aritmética",
    "href": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-média-aritmética",
    "title": "Análise de dados",
    "section": "Medida de centralidade: média aritmética",
    "text": "Medida de centralidade: média aritmética\n\nSoma dividida pelo tamanho da amostra: \\(\\mu_x = \\frac{\\sum_{i = 1}^{n} x_i}{n}\\)\nChamada de primeiro momento da distribuição ou valor esperado\nA média é significativa para distribuições simétricas\n\nMas é sensível a outliers, principalmente se a amostra é pequena"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-variações-da-média",
    "href": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-variações-da-média",
    "title": "Análise de dados",
    "section": "Medida de centralidade: variações da média",
    "text": "Medida de centralidade: variações da média\n\nA média truncada (trimmed mean) remove os \\(p\\) menores e os \\(p\\) maiores valores antes de calcular a média\n\nAjuda a tirar o viés de valores extremos\n\n\n\\[\\text{Trimmed mean} = \\frac{\\sum^{n-p}_{i=p+1} x_i}{n − 2p}\\]"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-variações-da-média-1",
    "href": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-variações-da-média-1",
    "title": "Análise de dados",
    "section": "Medida de centralidade: variações da média",
    "text": "Medida de centralidade: variações da média\n\nA média ponderada (weighted mean) considera um peso \\(w\\) para cada valor\n\nExemplo: para calcular incidência média de covid-19 nos estados do Brasil, devem considerar a população de cada estado como peso\n\n\n\\[\\text{Weighted mean} = \\frac{\\sum^{n}_{i=1} w_i x_i}{\\sum{w_i}}\\]"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-mediana",
    "href": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-mediana",
    "title": "Análise de dados",
    "section": "Medida de centralidade: mediana",
    "text": "Medida de centralidade: mediana\n\nValor do meio dos dados ordenados (2o quartil ou 50-percentil)\n\nEx: [1, 4, 4, 6, 7, 9, 14] # Mediana: \\(6\\)\n\nSe o tamanho for par, a mediana é a média dos dois valores do meio\n\nEx: [2, 5, 8, 10, 15, 16] # Mediana: \\(\\frac{8+10}{2} = 9\\)\nÉ mais resistente a outliers, mas descarta muita informação"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-moda",
    "href": "2-eda/2-estatistica-descritiva.html#medida-de-centralidade-moda",
    "title": "Análise de dados",
    "section": "Medida de centralidade: moda 😎",
    "text": "Medida de centralidade: moda 😎\n\nÉ o valor que detém o maior número de observações\n\nOu seja, o valor ou valores mais frequentes\nNo gráfico de barras ou histograma, ele é a maior barra\nTambém é resistente a outliers, mas descarta muita informação"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#efeito-de-outliers-na-média",
    "href": "2-eda/2-estatistica-descritiva.html#efeito-de-outliers-na-média",
    "title": "Análise de dados",
    "section": "Efeito de outliers na média",
    "text": "Efeito de outliers na média\n\nimport pandas as pd\n\nx = pd.Series([1.2, 1.3, 1.5, 1.4, 1.5, 1.7, 1.4, 1.5, 1.6, 1.5, 1.4, 1.5, 1.5,\n               1.9, 1.7, 1.6, 1.8, 1.9, 1.7, 1.6, 1.8, 1.9, 1.7, 1.6, 1.7, 1.8,\n               1.6, 1.5, 1.4, 1.8, 1.6, 1.5, 1.6, 1.7, 1.5, 1.3, 1.4, 1.5, 1.5, 120])\nprint(f\"Média: {x.mean()} / Mediana: {x.median()} / Moda: {float(x.mode())}\")\n\nMédia: 4.54 / Mediana: 1.6 / Moda: 1.5\n\n\n\nx_f = x[x < 5]\nprint(f\"Média: {x_f.mean()} / Mediana: {x_f.median()} / Moda: {float(x_f.mode())}\")\n\nMédia: 1.5794871794871794 / Mediana: 1.6 / Moda: 1.5"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#qual-métrica-usar",
    "href": "2-eda/2-estatistica-descritiva.html#qual-métrica-usar",
    "title": "Análise de dados",
    "section": "Qual métrica usar?",
    "text": "Qual métrica usar?\n\n\n\n\n\nTipo de variável / escala\nÍndice de tendência central\n\n\n\n\nCategórica nominal\nModa\n\n\nCategórica ordinal\nMediana\n\n\nContínua Simétrica e sem outliers\nMédia\n\n\nContínua Assimétrica ou com outliers\nMediana\n\n\n\n\n\n\n\nBill Gates adiciona $250 à renda média, mas não muda mediana\nNo geral: se histograma é enviesado, usar mediana. Caso contrário, usar a média"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#exemplo-medidas-de-centralidade",
    "href": "2-eda/2-estatistica-descritiva.html#exemplo-medidas-de-centralidade",
    "title": "Análise de dados",
    "section": "Exemplo: medidas de centralidade",
    "text": "Exemplo: medidas de centralidade\n\n\n\nDados de população e taxa de homicídios nos EUA:\n\n\n\n             State  Population  Murder.Rate Abbreviation\n0          Alabama     4779736          5.7           AL\n1           Alaska      710231          5.6           AK\n2          Arizona     6392017          4.7           AZ\n3         Arkansas     2915918          5.6           AR\n4       California    37253956          4.4           CA\n5         Colorado     5029196          2.8           CO\n6      Connecticut     3574097          2.4           CT\n7         Delaware      897934          5.8           DE\n8          Florida    18801310          5.8           FL\n9          Georgia     9687653          5.7           GA\n10          Hawaii     1360301          1.8           HI\n11           Idaho     1567582          2.0           ID\n12        Illinois    12830632          5.3           IL\n13         Indiana     6483802          5.0           IN\n14            Iowa     3046355          1.9           IA\n15          Kansas     2853118          3.1           KS\n16        Kentucky     4339367          3.6           KY\n17       Louisiana     4533372         10.3           LA\n18           Maine     1328361          1.6           ME\n19        Maryland     5773552          6.1           MD\n20   Massachusetts     6547629          2.0           MA\n21        Michigan     9883640          5.4           MI\n22       Minnesota     5303925          1.6           MN\n23     Mississippi     2967297          8.6           MS\n24        Missouri     5988927          6.6           MO\n25         Montana      989415          3.6           MT\n26        Nebraska     1826341          2.9           NE\n27          Nevada     2700551          6.0           NV\n28   New Hampshire     1316470          0.9           NH\n29      New Jersey     8791894          3.9           NJ\n30      New Mexico     2059179          4.8           NM\n31        New York    19378102          3.1           NY\n32  North Carolina     9535483          5.1           NC\n33    North Dakota      672591          3.0           ND\n34            Ohio    11536504          4.0           OH\n35        Oklahoma     3751351          4.5           OK\n36          Oregon     3831074          2.0           OR\n37    Pennsylvania    12702379          4.8           PA\n38    Rhode Island     1052567          2.4           RI\n39  South Carolina     4625364          6.4           SC\n40    South Dakota      814180          2.3           SD\n41       Tennessee     6346105          5.7           TN\n42           Texas    25145561          4.4           TX\n43            Utah     2763885          2.3           UT\n44         Vermont      625741          1.6           VT\n45        Virginia     8001024          4.1           VA\n46      Washington     6724540          2.5           WA\n47   West Virginia     1852994          4.0           WV\n48       Wisconsin     5686986          2.9           WI\n49         Wyoming      563626          2.7           WY\n\n\n\n\nMédia da População\n\n\nstate['Population'].mean()\n\n6162876.3\n\n\n\nMédia truncada (10%)\n\n\nfrom scipy.stats import trim_mean\ntrim_mean(state['Population'], 0.1)\n\n4783697.125\n\n\n\nMediana\n\n\nstate['Population'].median()\n\n4436369.5"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#exemplo-medidas-de-centralidade-1",
    "href": "2-eda/2-estatistica-descritiva.html#exemplo-medidas-de-centralidade-1",
    "title": "Análise de dados",
    "section": "Exemplo: medidas de centralidade",
    "text": "Exemplo: medidas de centralidade\n\n\n\nDados de população e taxa de homicídios nos EUA\n\n\n\n             State  Population  Murder.Rate Abbreviation\n0          Alabama     4779736          5.7           AL\n1           Alaska      710231          5.6           AK\n2          Arizona     6392017          4.7           AZ\n3         Arkansas     2915918          5.6           AR\n4       California    37253956          4.4           CA\n5         Colorado     5029196          2.8           CO\n6      Connecticut     3574097          2.4           CT\n7         Delaware      897934          5.8           DE\n8          Florida    18801310          5.8           FL\n9          Georgia     9687653          5.7           GA\n10          Hawaii     1360301          1.8           HI\n11           Idaho     1567582          2.0           ID\n12        Illinois    12830632          5.3           IL\n13         Indiana     6483802          5.0           IN\n14            Iowa     3046355          1.9           IA\n15          Kansas     2853118          3.1           KS\n16        Kentucky     4339367          3.6           KY\n17       Louisiana     4533372         10.3           LA\n18           Maine     1328361          1.6           ME\n19        Maryland     5773552          6.1           MD\n20   Massachusetts     6547629          2.0           MA\n21        Michigan     9883640          5.4           MI\n22       Minnesota     5303925          1.6           MN\n23     Mississippi     2967297          8.6           MS\n24        Missouri     5988927          6.6           MO\n25         Montana      989415          3.6           MT\n26        Nebraska     1826341          2.9           NE\n27          Nevada     2700551          6.0           NV\n28   New Hampshire     1316470          0.9           NH\n29      New Jersey     8791894          3.9           NJ\n30      New Mexico     2059179          4.8           NM\n31        New York    19378102          3.1           NY\n32  North Carolina     9535483          5.1           NC\n33    North Dakota      672591          3.0           ND\n34            Ohio    11536504          4.0           OH\n35        Oklahoma     3751351          4.5           OK\n36          Oregon     3831074          2.0           OR\n37    Pennsylvania    12702379          4.8           PA\n38    Rhode Island     1052567          2.4           RI\n39  South Carolina     4625364          6.4           SC\n40    South Dakota      814180          2.3           SD\n41       Tennessee     6346105          5.7           TN\n42           Texas    25145561          4.4           TX\n43            Utah     2763885          2.3           UT\n44         Vermont      625741          1.6           VT\n45        Virginia     8001024          4.1           VA\n46      Washington     6724540          2.5           WA\n47   West Virginia     1852994          4.0           WV\n48       Wisconsin     5686986          2.9           WI\n49         Wyoming      563626          2.7           WY\n\n\n\n\nMédia da Taxa de homicídios\n\n\nstate['Murder.Rate'].mean()\n\n4.066\n\n\n\nProblema: na média aritmética os estados têm mesmo peso\n\nSolução: média ponderada pela população\n\nMédia ponderada\n\n\nfrom numpy import average\naverage(state['Murder.Rate'], weights=state['Population'])\n\n4.445833981123393"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#sumariando-variabilidade",
    "href": "2-eda/2-estatistica-descritiva.html#sumariando-variabilidade",
    "title": "Análise de dados",
    "section": "Sumariando variabilidade",
    "text": "Sumariando variabilidade\n“Então há um homem que morreu afogado atravessando um riacho com uma profundidade média de seis polegadas”\n\n\nA tendência central não é suficiente\nPodemos adicionar a ela um índice de dispersão:\n\nRange / Intervalo (ex: valores mínimo e máximo)\nVariância / Desvio padrão / Coeficiente de variação\nPercentis extremos (ex: 10-percentil e 90-percentil)\nIntervalo semi-quartis (SIQR)"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#sumariando-a-variabilidade",
    "href": "2-eda/2-estatistica-descritiva.html#sumariando-a-variabilidade",
    "title": "Análise de dados",
    "section": "Sumariando a variabilidade",
    "text": "Sumariando a variabilidade\n\nHistograma do desempenho de dois sistemas:\n\n\n\n\n\nA média é a mesma. Mas qual você prefere?"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#range",
    "href": "2-eda/2-estatistica-descritiva.html#range",
    "title": "Análise de dados",
    "section": "Range",
    "text": "Range\nIntervalo: [min, max]\n\nÚtil apenas quando os valores de uma variavél são limitados (bounded)\n\nDá para ter noção desses limites com o range\n\nVaria de acordo com o número de observações\n\nNão dá para saber se o range é significativo ou não"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#variância-e-desvio-padrão",
    "href": "2-eda/2-estatistica-descritiva.html#variância-e-desvio-padrão",
    "title": "Análise de dados",
    "section": "Variância e desvio padrão",
    "text": "Variância e desvio padrão\nVariância amostral (unidade dos dados ao quadrado):\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}\\]\nDesvio padrão amostral (mesma unidade dos dados):\n\\[s = \\sqrt{s^2}\\]\nCoeficiente de variação (independente da média e da unidade):\n\\[COV = \\bar{C} = \\frac{s}{\\bar{x}}\\]"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#quantis",
    "href": "2-eda/2-estatistica-descritiva.html#quantis",
    "title": "Análise de dados",
    "section": "Quantis",
    "text": "Quantis\n\n0,05-quantil; 0,95-quantil: similar ao range\nDecis \\((\\frac{1}{10})\\), Quartis \\((\\frac{1}{4})\\)\nIntervalos entre quartis\n\nInter-Quartile Range: \\[\\mathit{IQR} = Q3 - Q1\\]\nSemi IQR: \\[\\mathit{SIQR} = \\frac{Q3 - Q1}{2}\\]"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#top-frequent",
    "href": "2-eda/2-estatistica-descritiva.html#top-frequent",
    "title": "Análise de dados",
    "section": "Top frequent",
    "text": "Top frequent\n\nPara dados categóricos, a dispersão pode ser a porcentagem de observações das categorias mais frequentes\nExemplo: top 90%, top 45%\n\nQual está mais espalhado?"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#como-selecionar-um-índice-de-dispersão",
    "href": "2-eda/2-estatistica-descritiva.html#como-selecionar-um-índice-de-dispersão",
    "title": "Análise de dados",
    "section": "Como selecionar um índice de dispersão?",
    "text": "Como selecionar um índice de dispersão?\n\n\n\n\n\nTipo de variável\nÍndice de dispersão\n\n\n\n\nCategórica\nTop frequent\n\n\nContínua Simétrica\nVariância, desvio padrão ou COV\n\n\nContínua Assimétrica\nQuantis, IQR ou SIQR\n\n\n\n\n\n\n\nIntervalo (range) pode ser usado para complementar a análise de dispersão"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#exemplos---índices-de-dispersão",
    "href": "2-eda/2-estatistica-descritiva.html#exemplos---índices-de-dispersão",
    "title": "Análise de dados",
    "section": "Exemplos - Índices de dispersão",
    "text": "Exemplos - Índices de dispersão"
  },
  {
    "objectID": "2-eda/2-estatistica-descritiva.html#referências",
    "href": "2-eda/2-estatistica-descritiva.html#referências",
    "title": "Análise de dados",
    "section": "Referências",
    "text": "Referências\n\nSlides baseados no material de:\n\nProf. Raquel Lopes (UFCG)\nProf. Steven Skiena (Stony Brok University)\n\nOutras referências:\n\nProbability and Statistics for Engineering and the Sciences. Jay Devore\nThe Art of Computer Systems Performance Analysis. Raj Jain"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de Dados I @ DCX / CCAE / UFPB",
    "section": "",
    "text": "Material da disciplina de Análise de Dados I"
  },
  {
    "objectID": "index.html#introdução",
    "href": "index.html#introdução",
    "title": "Análise de Dados I @ DCX / CCAE / UFPB",
    "section": "Introdução",
    "text": "Introdução\n\n1.1 Introdução à análise de dados (Slides)\n1.2 Introdução ao Python e Jupyter Notebook (Atividade)\n1.3 Introdução ao Pandas (Notebook)\n1.4 Exemplo com Pandas: análise de notas (Notebook)\nLaboratório 1: Manipulação de dados (GitHub)"
  },
  {
    "objectID": "index.html#análise-exploratória-de-dados",
    "href": "index.html#análise-exploratória-de-dados",
    "title": "Análise de Dados I @ DCX / CCAE / UFPB",
    "section": "Análise Exploratória de Dados",
    "text": "Análise Exploratória de Dados\n\n2.1 Introdução à Análise Exploratória de Dados (Slides)"
  },
  {
    "objectID": "1-introducao/3-intro-pandas.html",
    "href": "1-introducao/3-intro-pandas.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Referências\n\nPython for Data Analysis - 5 Getting Started with pandas"
  },
  {
    "objectID": "1-introducao/4-exemplo-pandas.html",
    "href": "1-introducao/4-exemplo-pandas.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Vamos usar um exemplo de análise para demonstrar mais funções da biblioteca Pandas de Python.\n\n\nO primeiro passo será carregar os dados que estão armazenados em um arquivo CSV. O arquivo que possui as notas das 4 unidades da disciplina Sistemas Operacionais no período 2017.1. O parâmetro index_col=\"id\" indica que a coluna id que consta no arquivo será o identificar das linhas do DataFrame.\n\nimport numpy as np\nimport pandas as pd\n\nso_20171 = pd.read_csv(\"../dados/notas_so_20171.csv\")\nso_20171\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n    \n    \n      5\n      6\n      9.6\n      9.8\n      10.0\n      9.0\n    \n    \n      6\n      7\n      9.0\n      8.5\n      8.5\n      8.0\n    \n    \n      7\n      8\n      4.0\n      7.5\n      5.3\n      2.0\n    \n    \n      8\n      9\n      10.0\n      9.9\n      9.6\n      9.1\n    \n    \n      9\n      10\n      8.3\n      8.7\n      8.0\n      6.7\n    \n    \n      10\n      11\n      10.0\n      10.0\n      8.5\n      9.8\n    \n    \n      11\n      12\n      7.3\n      9.0\n      7.8\n      7.0\n    \n    \n      12\n      13\n      8.8\n      9.2\n      10.0\n      8.7\n    \n    \n      13\n      14\n      6.5\n      8.6\n      7.0\n      4.0\n    \n    \n      14\n      15\n      10.0\n      8.5\n      8.1\n      8.5\n    \n    \n      15\n      16\n      9.7\n      10.0\n      7.7\n      7.5\n    \n    \n      16\n      17\n      8.3\n      9.7\n      8.7\n      6.8\n    \n    \n      17\n      18\n      7.5\n      9.4\n      6.0\n      7.2\n    \n    \n      18\n      19\n      9.3\n      9.9\n      9.8\n      9.1\n    \n    \n      19\n      20\n      0.0\n      2.5\n      1.0\n      0.0\n    \n    \n      20\n      21\n      5.0\n      8.0\n      5.8\n      4.8\n    \n  \n\n\n\n\nPodemos usar o comando info() para obter informações sobre os tipos das colunas e a presença de dados nulos:\n\nso_20171.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21 entries, 0 to 20\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   id      21 non-null     int64  \n 1   nota_1  21 non-null     float64\n 2   nota_2  21 non-null     float64\n 3   nota_3  21 non-null     float64\n 4   nota_4  21 non-null     float64\ndtypes: float64(4), int64(1)\nmemory usage: 968.0 bytes\n\n\nOutra função útil é a describe(), que calcula estatísticas básicas para as colunas de um DataFrame:\n\nso_20171.describe()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      count\n      21.000000\n      21.000000\n      21.000000\n      21.000000\n      21.000000\n    \n    \n      mean\n      11.000000\n      7.595238\n      8.438095\n      7.771429\n      6.742857\n    \n    \n      std\n      6.204837\n      2.408003\n      2.020266\n      2.242129\n      2.510492\n    \n    \n      min\n      1.000000\n      0.000000\n      2.500000\n      1.000000\n      0.000000\n    \n    \n      25%\n      6.000000\n      7.000000\n      8.000000\n      7.000000\n      5.100000\n    \n    \n      50%\n      11.000000\n      8.300000\n      9.000000\n      8.100000\n      7.200000\n    \n    \n      75%\n      16.000000\n      9.300000\n      9.800000\n      9.600000\n      8.700000\n    \n    \n      max\n      21.000000\n      10.000000\n      10.000000\n      10.000000\n      9.800000\n    \n  \n\n\n\n\nJá vimos que para calcular a média das notas de cada unidade podemos fazer:\n\nso_20171.mean(numeric_only=True)\n\nid        11.000000\nnota_1     7.595238\nnota_2     8.438095\nnota_3     7.771429\nnota_4     6.742857\ndtype: float64\n\n\nSuponha que queremos calcular a média das notas de cada uma das 4 unidades para todas as turmas de SO nos últimos 10 períodos. Para fazer do modo acima, precisaríamos de pelo menos 10 linhas de código, uma para cada turma. Isso não parece muito interessante. O jeito mais eficiente de fazer isso é juntar todos os dados em uma única tabela e aplicar funções em grupos de dados.\nVamos fazer um exemplo carregando os dados de mais um período (2017.2):\n\nso_20172 = pd.read_csv(\"../dados/notas_so_20172.csv\")\nso_20172\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n    \n    \n      5\n      6\n      6.6\n      6.7\n      7.2\n      3.8\n    \n    \n      6\n      7\n      9.3\n      9.0\n      9.2\n      8.5\n    \n    \n      7\n      8\n      9.0\n      10.0\n      8.7\n      8.1\n    \n    \n      8\n      9\n      7.8\n      8.5\n      9.0\n      7.5\n    \n    \n      9\n      10\n      7.5\n      8.0\n      9.0\n      5.3\n    \n    \n      10\n      11\n      8.3\n      9.0\n      5.2\n      6.2\n    \n    \n      11\n      12\n      7.5\n      9.8\n      8.2\n      6.0\n    \n    \n      12\n      13\n      7.7\n      7.3\n      4.5\n      6.5\n    \n    \n      13\n      14\n      5.8\n      7.5\n      6.5\n      6.2\n    \n    \n      14\n      15\n      7.8\n      9.3\n      8.8\n      4.5\n    \n    \n      15\n      16\n      0.0\n      2.5\n      2.0\n      3.5\n    \n    \n      16\n      17\n      5.8\n      8.3\n      7.5\n      3.5\n    \n    \n      17\n      18\n      9.6\n      9.0\n      10.0\n      5.5\n    \n    \n      18\n      19\n      7.0\n      6.7\n      6.6\n      8.0\n    \n    \n      19\n      20\n      7.3\n      8.6\n      7.3\n      0.0\n    \n    \n      20\n      21\n      9.5\n      8.8\n      7.8\n      6.2\n    \n    \n      21\n      22\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      22\n      23\n      7.3\n      8.0\n      6.7\n      7.5\n    \n    \n      23\n      24\n      9.5\n      8.8\n      7.0\n      8.3\n    \n    \n      24\n      25\n      9.7\n      9.0\n      3.4\n      7.4\n    \n    \n      25\n      26\n      8.9\n      6.7\n      5.5\n      4.5\n    \n  \n\n\n\n\n\n\n\nNote que a sua estrutura é semelhante à do DataFrame anterior. Desta forma, podemos juntá-los em um único data frame. Antes disso, temos que adicionar uma nova coluna que identifique o período que as notas se referem:\n\nso_20171[\"periodo\"] = \"2017.1\"\nso_20171.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n      2017.1\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n      2017.1\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n      2017.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n      2017.1\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n      2017.1\n    \n  \n\n\n\n\n\nso_20172[\"periodo\"] = \"2017.2\"\nso_20172.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n      2017.2\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n      2017.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n      2017.2\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n      2017.2\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n      2017.2\n    \n  \n\n\n\n\nO comando head() mostra apenas as primeiras linhas da tabela.\nComo os dois DataFrames possuem as mesmas colunas, podemos juntá-los com a função concat:\n\nso = pd.concat([so_20171, so_20172])\nso\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n      2017.1\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n      2017.1\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n      2017.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n      2017.1\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n      2017.1\n    \n    \n      5\n      6\n      9.6\n      9.8\n      10.0\n      9.0\n      2017.1\n    \n    \n      6\n      7\n      9.0\n      8.5\n      8.5\n      8.0\n      2017.1\n    \n    \n      7\n      8\n      4.0\n      7.5\n      5.3\n      2.0\n      2017.1\n    \n    \n      8\n      9\n      10.0\n      9.9\n      9.6\n      9.1\n      2017.1\n    \n    \n      9\n      10\n      8.3\n      8.7\n      8.0\n      6.7\n      2017.1\n    \n    \n      10\n      11\n      10.0\n      10.0\n      8.5\n      9.8\n      2017.1\n    \n    \n      11\n      12\n      7.3\n      9.0\n      7.8\n      7.0\n      2017.1\n    \n    \n      12\n      13\n      8.8\n      9.2\n      10.0\n      8.7\n      2017.1\n    \n    \n      13\n      14\n      6.5\n      8.6\n      7.0\n      4.0\n      2017.1\n    \n    \n      14\n      15\n      10.0\n      8.5\n      8.1\n      8.5\n      2017.1\n    \n    \n      15\n      16\n      9.7\n      10.0\n      7.7\n      7.5\n      2017.1\n    \n    \n      16\n      17\n      8.3\n      9.7\n      8.7\n      6.8\n      2017.1\n    \n    \n      17\n      18\n      7.5\n      9.4\n      6.0\n      7.2\n      2017.1\n    \n    \n      18\n      19\n      9.3\n      9.9\n      9.8\n      9.1\n      2017.1\n    \n    \n      19\n      20\n      0.0\n      2.5\n      1.0\n      0.0\n      2017.1\n    \n    \n      20\n      21\n      5.0\n      8.0\n      5.8\n      4.8\n      2017.1\n    \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n      2017.2\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n      2017.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n      2017.2\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n      2017.2\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n      2017.2\n    \n    \n      5\n      6\n      6.6\n      6.7\n      7.2\n      3.8\n      2017.2\n    \n    \n      6\n      7\n      9.3\n      9.0\n      9.2\n      8.5\n      2017.2\n    \n    \n      7\n      8\n      9.0\n      10.0\n      8.7\n      8.1\n      2017.2\n    \n    \n      8\n      9\n      7.8\n      8.5\n      9.0\n      7.5\n      2017.2\n    \n    \n      9\n      10\n      7.5\n      8.0\n      9.0\n      5.3\n      2017.2\n    \n    \n      10\n      11\n      8.3\n      9.0\n      5.2\n      6.2\n      2017.2\n    \n    \n      11\n      12\n      7.5\n      9.8\n      8.2\n      6.0\n      2017.2\n    \n    \n      12\n      13\n      7.7\n      7.3\n      4.5\n      6.5\n      2017.2\n    \n    \n      13\n      14\n      5.8\n      7.5\n      6.5\n      6.2\n      2017.2\n    \n    \n      14\n      15\n      7.8\n      9.3\n      8.8\n      4.5\n      2017.2\n    \n    \n      15\n      16\n      0.0\n      2.5\n      2.0\n      3.5\n      2017.2\n    \n    \n      16\n      17\n      5.8\n      8.3\n      7.5\n      3.5\n      2017.2\n    \n    \n      17\n      18\n      9.6\n      9.0\n      10.0\n      5.5\n      2017.2\n    \n    \n      18\n      19\n      7.0\n      6.7\n      6.6\n      8.0\n      2017.2\n    \n    \n      19\n      20\n      7.3\n      8.6\n      7.3\n      0.0\n      2017.2\n    \n    \n      20\n      21\n      9.5\n      8.8\n      7.8\n      6.2\n      2017.2\n    \n    \n      21\n      22\n      2.0\n      0.0\n      1.0\n      2.0\n      2017.2\n    \n    \n      22\n      23\n      7.3\n      8.0\n      6.7\n      7.5\n      2017.2\n    \n    \n      23\n      24\n      9.5\n      8.8\n      7.0\n      8.3\n      2017.2\n    \n    \n      24\n      25\n      9.7\n      9.0\n      3.4\n      7.4\n      2017.2\n    \n    \n      25\n      26\n      8.9\n      6.7\n      5.5\n      4.5\n      2017.2\n    \n  \n\n\n\n\nE se quisermos saber as médias de cada período específico, usando a tabela com todas as notas? Vamos mostrar duas formas de fazer isso.\n\n\n\nPodemos filtrar os dados de cada período e em seguida calcular a média da unidade 1:\n\nso[so[\"periodo\"] == \"2017.1\"][\"nota_1\"].mean()\n\n7.595238095238097\n\n\n\nso[so[\"periodo\"] == \"2017.2\"][\"nota_1\"].mean()\n\n7.457692307692308\n\n\nDa mesma forma, podemos ver a fração de alunos com nota acima da média na unidade 1:\n\nlen(so[(so[\"periodo\"] == \"2017.1\") & (so[\"nota_1\"] >= 7)].index) / len(so[(so[\"periodo\"] == \"2017.1\")].index)\n\n0.7619047619047619\n\n\n\n len(so[(so[\"periodo\"] == \"2017.2\") & (so[\"nota_1\"] >= 7)].index) / len(so[(so[\"periodo\"] == \"2017.2\")].index)\n\n0.7307692307692307\n\n\nExiste uma forma mais adequada para fazer esse tipo de cálculo agrupado por categoria.\n\n\n\nA função groupby agrupa os dados de acordo com categorias definidas pelas colunas e aplica funções para cada grupo. A função summarise aplica uma função para cada grupo de dados, gerando novas colunas no data frame.\nVamos usar como exemplo o cálculo da média para cada unidade, agrupado por período:\n\nso_media = so.groupby([\"periodo\"]).mean()\nso_media\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n    \n      periodo\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2017.1\n      11.0\n      7.595238\n      8.438095\n      7.771429\n      6.742857\n    \n    \n      2017.2\n      13.5\n      7.457692\n      7.876923\n      6.996154\n      5.892308\n    \n  \n\n\n\n\nComo fazemos então para calcular a fração de aprovados na unidade 1 para cada período?\n\ndef prop_aprovados(df, col=\"nota_1\", nota_aprovacao=7):\n    return len(df[df[\"nota_1\"] >= nota_aprovacao].index) / len(df.index)\n    \nso.groupby([\"periodo\"]).apply(prop_aprovados)\n\nperiodo\n2017.1    0.761905\n2017.2    0.730769\ndtype: float64\n\n\nAinda temos um incoveniente: ainda precisamos fazer cálculos especificando cada unidade que pretendemos observar. Além disso, se em algum dos períodos tivermos disciplinas com uma quantidade diferente de unidades (3 ao invés de 4) teríamos problemas com a estrutura atual. Vamos ver a seguir como organizar os dados de uma forma ainda mais adequada.\n\n\n\nVamos carregar os dados de outras duas disciplinas, Sistemas Distribuídos e Avaliação de Desempenho, aproveitando para adicionar o nome da disciplina e o período no data frame:\n\nads_20171 = pd.read_csv(\"../dados/notas_ads_20171.csv\")\nads_20171[\"disciplina\"] = \"Avaliação de Desempenho de Sistemas\"\nads_20171[\"periodo\"] = \"2017.1\"\nads_20171.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      disciplina\n      periodo\n    \n  \n  \n    \n      0\n      1\n      9.8\n      7.0\n      5.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      1\n      2\n      8.8\n      9.7\n      3.5\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      2\n      3\n      9.5\n      7.0\n      8.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      3\n      4\n      7.0\n      9.8\n      9.8\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      4\n      5\n      3.5\n      8.8\n      9.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n  \n\n\n\n\n\nsd_20172 = pd.read_csv(\"../dados/notas_sd_20172.csv\")\nsd_20172[\"disciplina\"] = \"Sistemas Distribuidos\"\nsd_20172[\"periodo\"] = \"2017.2\"\nsd_20172.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      disciplina\n      periodo\n    \n  \n  \n    \n      0\n      1\n      6.8\n      8.0\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      1\n      2\n      4.2\n      3.0\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      2\n      3\n      0.0\n      0.0\n      0.0\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      3\n      4\n      8.0\n      7.5\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      4\n      5\n      7.0\n      7.5\n      10.0\n      Sistemas Distribuidos\n      2017.2\n    \n  \n\n\n\n\nPodemos juntar as notas de todas as disciplinas para facilitar o processamento. Mas temos um problema: as disciplinas de SO têm notas de 4 unidades, enquanto as de ADS e SD só têm 3 unidades. Além disso, ter uma coluna na tabela para cada unidade nos força a ter que especificar para qual unidade queremos calcular estatísticas. E se uma disciplina tiver 10 unidades (mini-testes, por exemplo), temos que ter 10 cálculos para calcular as médias de cada unidade?\nAi que entra o tidy data, que é uma forma de organizar os dados que facilita muito a análise usando as ferramentas de análise de dados.\nExistem 3 regras para uma tabela ser tidy:\n\nCada variável deve ter sua própria coluna.\nCada observação deve ter sua própria linha.\nCada valor deve ter sua própria célula.\n\nA figura abaixo mostra essas regras visualmente:\n\nComo transformar então nossas tabelas de notas no formato tidy? Um dos problems atuais é que a variável nota está espalhada em várias colunas: nota_1, nota_2, nota_3, … Temos outra variável implícita que está misturada com a variável nota que é a variável unidade, que pode indicar a qual unidade uma prova se refere. Desta forma, a tabela no formato tidy poderia ter uma coluna para a variável unidade e ter apenas uma coluna para a variável nota.\nVamos usar o Pandas para transformar os dados no formato tidy, usando funções de reshaping e pivot tables (leia este tutorial do Pandas para entender mais).\nPrimeiro para as notas de Sistemas Operacionais, vamos adicionar uma coluna com o nome da disciplina e transformar as colunas nota_1, nota_2, nota_3 e nota_4 em duas colunas: unidade e nota. Ou seja, um aluno da turma ao invés de ter as 4 notas em apenas uma linha, ele terá as notas distribuídas em 4 linhas, uma para cada unidade. Para isto, vamos usar a função do Pandas wide_to_long:\n\nso[\"disciplina\"] = \"Sistemas Operacionais\"\nso_tidy = pd.wide_to_long(so, stubnames='nota', i=['id', 'periodo', 'disciplina'],\n                          j='unidade', sep=\"_\")\nso_tidy\n\n\n\n\n\n  \n    \n      \n      \n      \n      \n      nota\n    \n    \n      id\n      periodo\n      disciplina\n      unidade\n      \n    \n  \n  \n    \n      1\n      2017.1\n      Sistemas Operacionais\n      1\n      8.3\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.3\n    \n    \n      4\n      8.0\n    \n    \n      2\n      2017.1\n      Sistemas Operacionais\n      1\n      7.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      25\n      2017.2\n      Sistemas Operacionais\n      4\n      7.4\n    \n    \n      26\n      2017.2\n      Sistemas Operacionais\n      1\n      8.9\n    \n    \n      2\n      6.7\n    \n    \n      3\n      5.5\n    \n    \n      4\n      4.5\n    \n  \n\n188 rows × 1 columns\n\n\n\nO parâmetro stubname='nota' indica que ele vai transformar as colunas que começam com a palavra “nota”. O parâmetro i=['id', 'periodo', 'disciplina'] indica as colunas que identificarão unicamente cada linha de observação (serão os índices). E o parâmetro j='unidade' indica o nome da nova coluna que será criada, onde os valores serão os números encontrados nas colunas nota_X, considerando que sep=\"_\" e os nomes das colunas têm o formato nota_unidade.\nFazendo isso agora para as outras disciplinas e concatenando tudo em um único DataFrame. Vamos também renomear o index id para id_aluno para melhor compreensão dos dados. O parâmetro inplace=True faz com que o DataFrame notas seja alterado ao invés de retornar um novo DataFrame com a alteração realizada.\n\nads_tidy = pd.wide_to_long(ads_20171, stubnames='nota', i=['id', 'periodo', 'disciplina'], j='unidade', sep=\"_\")\nsd_tidy = pd.wide_to_long(sd_20172, stubnames='nota', i=['id', 'periodo', 'disciplina'], j='unidade', sep=\"_\")\n\nnotas = pd.concat([so_tidy, ads_tidy, sd_tidy])\nnotas.index.set_names({'id': 'id_aluno'}, inplace=True)\n        \nnotas\n\n\n\n\n\n  \n    \n      \n      \n      \n      \n      nota\n    \n    \n      id_aluno\n      periodo\n      disciplina\n      unidade\n      \n    \n  \n  \n    \n      1\n      2017.1\n      Sistemas Operacionais\n      1\n      8.3\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.3\n    \n    \n      4\n      8.0\n    \n    \n      2\n      2017.1\n      Sistemas Operacionais\n      1\n      7.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23\n      2017.2\n      Sistemas Distribuidos\n      2\n      9.7\n    \n    \n      3\n      10.0\n    \n    \n      24\n      2017.2\n      Sistemas Distribuidos\n      1\n      9.8\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.5\n    \n  \n\n344 rows × 1 columns\n\n\n\nComo calcular agora a nota média para cada disciplina, período e unidade? Ficou bem mais fácil.\n\n\n\nnotas.groupby([\"disciplina\", \"periodo\", \"unidade\"]).mean()\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      unidade\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.939286\n    \n    \n      2\n      8.382143\n    \n    \n      3\n      7.425000\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      1\n      7.441667\n    \n    \n      2\n      6.729167\n    \n    \n      3\n      8.895833\n    \n    \n      Sistemas Operacionais\n      2017.1\n      1\n      7.595238\n    \n    \n      2\n      8.438095\n    \n    \n      3\n      7.771429\n    \n    \n      4\n      6.742857\n    \n    \n      2017.2\n      1\n      7.457692\n    \n    \n      2\n      7.876923\n    \n    \n      3\n      6.996154\n    \n    \n      4\n      5.892308\n    \n  \n\n\n\n\n\n\n\n\nmedia_alunos = notas.groupby([\"disciplina\", \"periodo\", \"id_aluno\"]).mean()\nmedia_alunos\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.266667\n    \n    \n      2\n      7.333333\n    \n    \n      3\n      8.166667\n    \n    \n      4\n      8.866667\n    \n    \n      5\n      7.100000\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n    \n    \n      23\n      7.375000\n    \n    \n      24\n      8.400000\n    \n    \n      25\n      7.375000\n    \n    \n      26\n      6.400000\n    \n  \n\n99 rows × 1 columns\n\n\n\n\n\n\n\nmedia_turma = media_alunos.groupby([\"disciplina\", \"periodo\"]).mean()\nmedia_turma\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      7.915476\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      7.688889\n    \n    \n      Sistemas Operacionais\n      2017.1\n      7.636905\n    \n    \n      2017.2\n      7.055769\n    \n  \n\n\n\n\n\n\n\nE se eu quiser calcular outras estatísticas como a quantidade de alunos, nota mínima, mediana, média e máxima? Podemos usar a função agg para aplicar várias funções de agregação nos dados.\n\ndef prop_aprovados(medias, min_media_aprovacao=5):\n    return medias[medias >= min_media_aprovacao].count() / medias.count()\n\n(\n    media_alunos\n    .groupby([\"disciplina\", \"periodo\"])\n    .agg(['count', 'min', 'median', 'mean', 'max', prop_aprovados])\n)\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      \n      \n      count\n      min\n      median\n      mean\n      max\n      prop_aprovados\n    \n    \n      disciplina\n      periodo\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      28\n      0.000\n      8.266667\n      7.915476\n      10.00\n      0.892857\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      24\n      0.000\n      8.250000\n      7.688889\n      10.00\n      0.916667\n    \n    \n      Sistemas Operacionais\n      2017.1\n      21\n      0.875\n      8.100000\n      7.636905\n      9.65\n      0.904762\n    \n    \n      2017.2\n      26\n      1.250\n      7.375000\n      7.055769\n      9.00\n      0.923077\n    \n  \n\n\n\n\nVocê também pode aplicar uma função própria, por exemplo a que calcula a proporção de alunos aprovados em cada disciplina, que conta as linhas apenas de alunos com nota maior ou igual à 5 e divide pela quantidade total de alunos dentro do grupo:\n\ndef prop_aprovados(medias, min_media_aprovacao=5):\n    return medias[medias >= min_media_aprovacao].count() / medias.count()\n\n(\n    media_alunos\n    .groupby([\"disciplina\", \"periodo\"])\n    .agg([prop_aprovados])\n\"APROVADO\" if media_alunos[\"nota\"] >= 5 else \"REPROVADO\")\n\nSyntaxError: invalid syntax (2677895194.py, line 8)\n\n\n\n\n\nVamos adicionar uma coluna na tabela indicando se o aluno foi aprovado por média ou não. Para isso, vamos criar a nova função e aplicá-la para cada linha do dataframe com a função apply:\n\ndef calcula_resultado(media):\n    return 'APROVADO' if media >= 5 else 'REPROVADO'\n\nmedia_alunos[\"resultado\"] = media_alunos[\"nota\"].apply(calcula_resultado)\nmedia_alunos\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n      resultado\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.266667\n      APROVADO\n    \n    \n      2\n      7.333333\n      APROVADO\n    \n    \n      3\n      8.166667\n      APROVADO\n    \n    \n      4\n      8.866667\n      APROVADO\n    \n    \n      5\n      7.100000\n      APROVADO\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n      REPROVADO\n    \n    \n      23\n      7.375000\n      APROVADO\n    \n    \n      24\n      8.400000\n      APROVADO\n    \n    \n      25\n      7.375000\n      APROVADO\n    \n    \n      26\n      6.400000\n      APROVADO\n    \n  \n\n99 rows × 2 columns\n\n\n\n\n\n\nA função sort_values ordena o dataframe com base nos valores de uma ou mais colunas. O parâmetro ascending=False é usado para indicar que a ordenação não será feita na ordem padrão ascendente (ou seja, será na ordem descendente do maior para o menor valor).\n\nmedia_alunos.sort_values('nota', ascending=False)\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n      resultado\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      9\n      10.000000\n      APROVADO\n    \n    \n      10\n      10.000000\n      APROVADO\n    \n    \n      23\n      10.000000\n      APROVADO\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      12\n      10.000000\n      APROVADO\n    \n    \n      9\n      9.933333\n      APROVADO\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n      REPROVADO\n    \n    \n      2017.1\n      20\n      0.875000\n      REPROVADO\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      8\n      0.666667\n      REPROVADO\n    \n    \n      3\n      0.000000\n      REPROVADO\n    \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      20\n      0.000000\n      REPROVADO\n    \n  \n\n99 rows × 2 columns\n\n\n\n\n\n\nPega o dataframe com a média dos alunos, ordena pela média em ordem decrescente, agrupa por turma (disciplina e período) e pega as 3 primeiras linhas de cada grupo.\n\n(\n    media_alunos\n    .sort_values('nota', ascending=False)\n    .groupby(['disciplina', 'periodo'])\n    .head(3)\n)\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      9\n      10.000000\n    \n    \n      10\n      10.000000\n    \n    \n      23\n      10.000000\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      12\n      10.000000\n    \n    \n      9\n      9.933333\n    \n    \n      23\n      9.900000\n    \n    \n      Sistemas Operacionais\n      2017.1\n      9\n      9.650000\n    \n    \n      6\n      9.600000\n    \n    \n      11\n      9.575000\n    \n    \n      2017.2\n      1\n      9.000000\n    \n    \n      7\n      9.000000\n    \n    \n      8\n      8.950000\n    \n  \n\n\n\n\nNote que organizamos a sequência de comandos com uma função por linha. Essa forma fica mais legível quando se tem muitos comandos seguidos. Como cada função retorna um dataframe, dá para encadear chamadas de funções dessa forma no Pandas. Para funcionar com um comando por linha é preciso colocar a sequência de funções entre parênteses.\n\n\n\n\nOutra utilidade do Pandas é pegar apenas “fatias” (slices) dos dados, seja filtrando linhas ou colunas. O pandas oferece a função .loc para fazer o slicing a partir dos índices e a função .iloc para filtrar com base no número da linha.\nPor exemplo, para pegar apenas as linhas que tem “Sistemas Operacionais” como primeiro índice (disciplina), podemos usar:\n\nmedia_alunos.loc[\"Sistemas Distribuidos\"]\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      2017.2\n      1\n      8.100000\n    \n    \n      2\n      5.566667\n    \n    \n      3\n      0.000000\n    \n    \n      4\n      8.333333\n    \n    \n      5\n      8.166667\n    \n    \n      6\n      9.533333\n    \n    \n      7\n      8.433333\n    \n    \n      8\n      0.666667\n    \n    \n      9\n      9.933333\n    \n    \n      10\n      6.266667\n    \n    \n      11\n      9.700000\n    \n    \n      12\n      10.000000\n    \n    \n      13\n      7.666667\n    \n    \n      14\n      6.033333\n    \n    \n      15\n      9.133333\n    \n    \n      16\n      7.266667\n    \n    \n      17\n      8.833333\n    \n    \n      18\n      7.566667\n    \n    \n      19\n      8.766667\n    \n    \n      20\n      9.833333\n    \n    \n      21\n      7.933333\n    \n    \n      22\n      7.800000\n    \n    \n      23\n      9.900000\n    \n    \n      24\n      9.100000\n    \n  \n\n\n\n\nE se quisermos pegar apenas as linhas 5 a 10 do DataFrame podemos usar:\n\nmedia_alunos.iloc[5:10]\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      6\n      8.200000\n    \n    \n      7\n      9.933333\n    \n    \n      8\n      3.766667\n    \n    \n      9\n      10.000000\n    \n    \n      10\n      10.000000\n    \n  \n\n\n\n\nPodemos também fazer um slice de linha e coluna ao mesmo tempo. Por exemplo, para filtrar as linhas com índices de 0 a 4 e a coluna nota_3, podemos fazer:\n\nso.loc[0:4, \"nota_3\"]\n\n0     9.3\n1     4.6\n2     7.7\n3     9.8\n4    10.0\nName: nota_3, dtype: float64\n\n\nOu para pegar o valor que está na linha 10 e coluna 3 (lembrando que Python indexa a partir do 0):\n\nso.iloc[10, 3]\n\n8.5\n\n\n\n\n\nTambém podemos exportar um dataframe pra um arquivo. Por exemplo, para exportar a tabela de média dos alunos para um arquivo podemos rodar:\nmedia_alunos.to_csv(\"../dados/notas_medias_alunos.csv\")"
  }
]