[
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-1",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-1",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 1",
    "text": "Conteúdo - Unidade 1\n\nIntrodução à análise de dados\n\nConceitos básicos\nIntrodução a ferramentas [Python, NumPy, Pandas, Jupyter]\nTratamento de dados\n\nCarregamento, limpeza, transformação\n\nVisualização básica\n\nExploratory Data Analysis (EDA)\n\nEstatística descritiva\nAnálise de correlação\nAnálise exploratória"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-2",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-2",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 2",
    "text": "Conteúdo - Unidade 2\n\nInferência estatística\n\nSignificância estatística e amostragem\nIntervalos de confiança\nTestes de hipótese\nTestes de permutação e p-valor\n\nRegressão\n\nRegressão linear simples\nRegressão linear multivariada\nRegressão logística"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#conteúdo---unidade-3",
    "href": "1-introducao/0-apresentacao.html#conteúdo---unidade-3",
    "title": "Análise de dados",
    "section": "Conteúdo - Unidade 3",
    "text": "Conteúdo - Unidade 3\n\nClustering\n\nMedidas de similaridade e divergência\nAgrupamento com K-means\nAgrupamento hierárquico\n\nVisualização de dados\nProjeto de análise de dados"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#avaliações",
    "href": "1-introducao/0-apresentacao.html#avaliações",
    "title": "Análise de dados",
    "section": "Avaliações",
    "text": "Avaliações\n\nUnidades 1 e 2:\n\nAtividades práticas de análise de dados\n\nRelatórios\nQuestionários\n\n\nUnidade 3:\n\nProjeto de análise de dados\n\nRelatório analítico (ex: blog post, artigo)\nAplicação web / mobile\nDashboard"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#referências-básicas",
    "href": "1-introducao/0-apresentacao.html#referências-básicas",
    "title": "Análise de dados",
    "section": "Referências básicas",
    "text": "Referências básicas\n\nPython for Data Analysis. McKinney. 3 ed, 2022 (online)\nThe Data Science Design Manual. Skienna. 2017 (pdf, slides)\nPython Data Science Handbook. VanderPlas. 2022 (online)\nPractical Statistics for Data Scientists. Bruce. 2 ed, 2020 (pdf)\nR for Data Science. Wickham. 2017 (online)\nThink Stats: Exploratory Data Analysis in Python. Downey, 2014 (online)"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#referências-complementares",
    "href": "1-introducao/0-apresentacao.html#referências-complementares",
    "title": "Análise de dados",
    "section": "Referências complementares",
    "text": "Referências complementares\n\nCiência de Dados com R (online)\nModern Dive: An Introduction to Statistical and Data sciences via R (online; slides)\nIntroductory Statistics with Randomization and Simulation\nExploratory Data Analysis with R\nR Programming for Data Science\nAn Introduction to Statistical Learning\nThe Art of Data Science\nOpenIntro Statistics"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#ambientes-virtuais",
    "href": "1-introducao/0-apresentacao.html#ambientes-virtuais",
    "title": "Análise de dados",
    "section": "Ambientes virtuais",
    "text": "Ambientes virtuais\n\nGoogle Classroom\n\nAvisos gerais, slides e outros materiais\nPrecisa estar logado com a conta do DCX\n\nDiscord\n\nAvisos, dúvidas, discussões\n\nGitHub Classroom\n\nMaterial para atividades práticas, envio de código e relatórios\nCriem uma conta no GitHub e aprendam git!"
  },
  {
    "objectID": "1-introducao/0-apresentacao.html#ferramentas-para-começar-a-brincar",
    "href": "1-introducao/0-apresentacao.html#ferramentas-para-começar-a-brincar",
    "title": "Análise de dados",
    "section": "Ferramentas para começar a brincar",
    "text": "Ferramentas para começar a brincar\n\nPython: linguagem de programação que usaremos no curso\nJupyter Notebook: criar documentos com código executável\nNumPy: biblioteca Python para computação numérica\nPandas: biblioteca Python para análise de dados\nMatplotlib, Seaborn: bibliotecas Python de visualização de dados\nVS Code: IDE usada nas aulas\n\nInstalar extensão Python for VS Code\n\nGoogle Colab: ambiente de execução de notebooks\n\nPode ser usado para executar código integrado ao Github\n\n\n\n\nProf. Marcus Carvalho @ DCX / CCAE / UFPB"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#tendências-de-busca",
    "href": "1-introducao/1-introducao-ad.html#tendências-de-busca",
    "title": "Análise de dados",
    "section": "Tendências de busca",
    "text": "Tendências de busca\n\nFonte: Google Trends"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#dados-to-informação-to-conhecimento-to-sabedoria",
    "href": "1-introducao/1-introducao-ad.html#dados-to-informação-to-conhecimento-to-sabedoria",
    "title": "Análise de dados",
    "section": "Dados \\(\\to\\) Informação \\(\\to\\) Conhecimento \\(\\to\\) Sabedoria",
    "text": "Dados \\(\\to\\) Informação \\(\\to\\) Conhecimento \\(\\to\\) Sabedoria\n\nFonte: The Application of Visual Analytics to Financial Stability Monitoring"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#conhecimento-é-poder",
    "href": "1-introducao/1-introducao-ad.html#conhecimento-é-poder",
    "title": "Análise de dados",
    "section": "Conhecimento é poder!",
    "text": "Conhecimento é poder!"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#quem-tem-interesse",
    "href": "1-introducao/1-introducao-ad.html#quem-tem-interesse",
    "title": "Análise de dados",
    "section": "Quem tem interesse?",
    "text": "Quem tem interesse?\n\nEmpresas querem insights para melhorar seus negócios\nCidadãos querem mais transparência de dados e informação\nGovernos querem mecanismos para melhorar fiscalização"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#o-que-é-análise-e-ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#o-que-é-análise-e-ciência-de-dados",
    "title": "Análise de dados",
    "section": "O que é análise e ciência de dados?",
    "text": "O que é análise e ciência de dados?\n\nComo toda área nova, não há definições muito claras\nAlgumas definições relacionadas da Gartner:\n\nBusiness Inteligence (BI): Aplicações, ferramentas e melhores práticas que permitem o acesso e a análise de informações para melhorar e otimizar decisões e desempenho.\nAnalytics: Processo de analizar informações de um domínio particular. Ou a aplicação de BI para uma área específica.\nBig data: Grande volume, velocidade e/ou variedade de dados que exigem processamento eficiente e inovador de informações permitindo insights, decisões e automação de processos.\nCientista de dados: Extrai insights de dados. Requer habilidades analíticas para detectar padrões."
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#ciência-de-dados",
    "title": "Análise de dados",
    "section": "Ciência de dados",
    "text": "Ciência de dados\n\n\n\nIncorpora elementos de:\n\nExploratory Data Analysis (EDA) e Visualização de dados;\nMachine Learning e Estatística;\nComputação de Alto Desempenho\n\nHabilidades necessárias:\n\nCiência da Computação\nMatemática e Estatística\nExpertise nos domínios da aplicação\n\n\n\n\n\n\nFonte: Steven Skiena - Lecture 1: Introduction to Data Science"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#por-que-ciência-de-dados-agora",
    "href": "1-introducao/1-introducao-ad.html#por-que-ciência-de-dados-agora",
    "title": "Análise de dados",
    "section": "Por que ciência de dados agora?",
    "text": "Por que ciência de dados agora?\n\n\nNovas tecnologias para processar dados em larga escala\n\nRedes sociais, IoT, Cloud Computing, Big Data, Machine Learning\n\nSucesso de análise de dados em empresas serviu de modelo\n\nGoogle, Facebook, Amazon, Microsoft"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#apreciando-dados",
    "href": "1-introducao/1-introducao-ad.html#apreciando-dados",
    "title": "Análise de dados",
    "section": "Apreciando dados",
    "text": "Apreciando dados\n\nCientistas da computação geralmente não apreciam dados\n\nSó é algo que eles carregam nos programas\nGeralmente usam dados aleatórios para testar programas\nConjuntos de dados interessantes são recursos raros, que requerem trabalho duro e imaginação para obtê-los"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#section",
    "href": "1-introducao/1-introducao-ad.html#section",
    "title": "Análise de dados",
    "section": "",
    "text": "Cientista real\n\n\nSe esforça para entender a bagunça do mundo real\nNada é completamente verdadeiro ou falso\nDirecionados a dados\nObsessão por descobrir\nUtiliza dados com erros\n\n\n\nCientista da computação\n\n\nConstroe seu próprio mundo virtual organizado\nTudo é completamente verdadeiro ou falso\nDirecionado a algoritmos\nObsessão por inventar\nUtiliza dados corretos\n\n\n\n\n\nCientistas de dados devem pensar como cientistas reais!"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#ciência-tradicional-x-ciência-de-dados",
    "href": "1-introducao/1-introducao-ad.html#ciência-tradicional-x-ciência-de-dados",
    "title": "Análise de dados",
    "section": "Ciência tradicional x ciência de dados",
    "text": "Ciência tradicional x ciência de dados\n\nCiência tradicional: formulação de hipóteses e obtenção de dados específicos para confirmá-las ou negá-las.\nCiência de dados: geração de dados em larga escala para realizar novas descobertas ao analisá-los.\nDuas formas importantes de pensar:\n\nDado um problema, quais dados ajudarão a resolvê-lo?\nDado um conjunto de dados, que problemas interessantes se aplicarão a ele?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#genialidade-x-sabedoria",
    "href": "1-introducao/1-introducao-ad.html#genialidade-x-sabedoria",
    "title": "Análise de dados",
    "section": "Genialidade x Sabedoria",
    "text": "Genialidade x Sabedoria\n\nDesenvolvedores são contratados para produzir código\nCientistas de dados são contratados para produzir insights\nGenialidade é saber encontrar a resposta correta\nSabedoria é saber evitar as respostas erradas!\nA sabedoria vem de:\n\nExperiência, conhecimento geral, ouvir os outros\nHumildade: observar quanto, como e porque você errou\n\n\n\nCiência de dados se beneficia mais de sábios que de gênios"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#desenvolvendo-a-curiosidade",
    "href": "1-introducao/1-introducao-ad.html#desenvolvendo-a-curiosidade",
    "title": "Análise de dados",
    "section": "Desenvolvendo a curiosidade",
    "text": "Desenvolvendo a curiosidade\n\nO bom cientista de dados desenvolve curiosidade sobre o domínio / aplicação que ele está trabalhando\nConversa com pessoas envolvidas nos dados que trabalha\nAcompanha notícias para ter uma visão ampla do mundo\nEles são encorajados a perguntar:\n\nQue coisas interessantes você consegue aprender de um certo conjunto de dados?\nQue coisas você realmente quer saber?\nQue conjunto de dados pode levar você a isso?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-dados-de-filmes-e-séries",
    "href": "1-introducao/1-introducao-ad.html#imdb-dados-de-filmes-e-séries",
    "title": "Análise de dados",
    "section": "IMDb: dados de filmes e séries",
    "text": "IMDb: dados de filmes e séries"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-dados-de-atores",
    "href": "1-introducao/1-introducao-ad.html#imdb-dados-de-atores",
    "title": "Análise de dados",
    "section": "IMDb: dados de atores",
    "text": "IMDb: dados de atores"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-perguntas-12",
    "href": "1-introducao/1-introducao-ad.html#imdb-perguntas-12",
    "title": "Análise de dados",
    "section": "IMDb: Perguntas? [1/2]",
    "text": "IMDb: Perguntas? [1/2]\n\nQuais atores atuaram em mais filmes? Nos melhores filmes? Ganharam mais dinheiro? Com carreiras mais longas?\nQuais os filmes com melhores/piores avaliações? Por ano? Por gênero? Mais caros? Com elencos mais poderosos?\nFilmes com maior faturamento recebem notas maiores e mais prêmios? É possível prever a nota e o faturamento?\nComo os filmes de Hollywood se comparam a filmes indianos em: avaliação, orçamento, rendimento? Filmes americanos são mais bem avaliados do que estrangeiros?"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#imdb-perguntas-22",
    "href": "1-introducao/1-introducao-ad.html#imdb-perguntas-22",
    "title": "Análise de dados",
    "section": "IMDb: Perguntas? [2/2]",
    "text": "IMDb: Perguntas? [2/2]\n\nComo é a rede social da participação de atores em filmes?\n\nExemplo: grafo que indica graus a partir de Kevin Bacon\n\nQual é a distribuição de idade de atores e atrizes em filmes? Atrizes tendem a ser mais jovens que atores?\nQuais gêneros de filmes recebem as melhores avaliações? Quais gêneros são mais caros? Quais faturam mais?\nQual a probabilidade de uma pessoa gostar de um filme? (Exemplo: recomendações do Netflix)"
  },
  {
    "objectID": "1-introducao/1-introducao-ad.html#referências",
    "href": "1-introducao/1-introducao-ad.html#referências",
    "title": "Análise de dados",
    "section": "Referências",
    "text": "Referências\n\nSkiena S.S. (2017) What is Data Science?. In: The Data Science Design Manual. Texts in Computer Science. Springer.\n\nCSE 519: Data Science - Steven Skiena - Lecture 1: Introduction to Data Science\n\n\n\n\nProf. Marcus Carvalho @ DCX / CCAE / UFPB"
  },
  {
    "objectID": "1-introducao/2-intro-python-jupyter.html",
    "href": "1-introducao/2-intro-python-jupyter.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Nós iremos usar a linguagem Python para demonstrações nas aulas e atividades práticas do curso. Espera-se que você já tenha algum contato com Python em disciplinas anteriores. Além disso, nós usaremos o Jupyter Notebook para criação de notebooks que servirão para fazer as atividades práticas e os relatórios de análise de dados.\nPara se familiarizar com as ferramentas e montar o ambiente de desenvolvimento necessário para o curso, nessa atividade vocês irão instalar o Python e o Jupyter Notebook e seguir um passo a passo de um Notebook para revisar os conceitos básicos dessas ferramentas. Além de conseguir rodar um notebook na sua máquina local, você também deve ser capaz de experimentar a execução de notebooks Jupyter em ambientes de execução na nuvem, como através do GitHub Codespaces e do Google Colab.\nNesta atividade, você deve seguir o passo a passo dos capítulos 2 - Python Language Basics, IPython, and Jupyter Notebooks e 3 - Built-In Data Structures, Functions, and Files do livro Python for Data Science, seguindo suas instruções através de notebooks dos capítulos.\nNo repositório do livro no GitHub o autor disponibiliza o Notebook reference a estes capítulos nos arquivos ch02.ipynb e ch03.ipynb. Nesta atividade, você deve ser capaz de abrir cada Notebook em um ambiente de execução e executar o seu código.\nAntes de começar, você deve:\n\nInstalar o Python\nInstalar o Jupyter Notebook\nInstalar o git\n\n\n\nVamos iniciar com a execução do Notebook do capítulo 2 (ch02.ipynb)\n\n\nPara rodar localmente, você deve baixar o arquivo ch02.ipynb para a sua máquina. Para isso, você pode fazer um clone do repositório que possui todos os notebooks do livro, rodando em um terminal:\ngit clone https://github.com/wesm/pydata-book \nEm seguida, entre no diretório do repositório e mude para a branch da 3a edição do livro, que iremos usar nas atividades, rodando:\ncd pydata-book\ngit checkout 3rd-edition\n\n\n\n\n\n\nDica\n\n\n\nSe não quiser baixar todo o repositório do livro, você pode fazer o download apenas do arquivo específico no repositório.\n\n\n\n\n\nNo diretório onde está o arquivo do notebook (pydata-book), inicie o Jupyter rodando no terminal:\njupyter notebook\nEste comando deve abrir um browser com o Jupyter Notebook em execução, como na imagem abaixo:\n\nLocalize o nome do arquivo do notebook ch02.ipynb e clique em seu nome para abrir.\nSe deu tudo certo, você deve ver uma tela como a de baixo:\n\nO notebook combina blocos de texto (Markdown) com blocos de código. Você deve fazer a leitura do notebook e ser capaz de executar todas as células que contêm código. Para executar uma célula de código, clique na célula para selecioná-la e clique no botão Run do menu acima. O código é apresentado no bloco In e a saída gerada pela execução do código é apresentada no bloco Out, conforme imagem abaixo.\n\nVocê deve seguir a execução dos blocos na sequência, porque pode existir uma dependência do código de baixo com o de cima. Se quiser rodar todas as células na sequência, você pode ir no menu Cell -> Run All. Verique se houve algum erro na execução de alguma célula, verificando as saídas que cada uma gerou.\nVocê também pode editar o conteúdo do notebook, alterando o código ou o texto dos blocos, ou adicionando novas células.\nInsira uma nova célula de código no final do notebook com código Python que imprime essa mensagem:\nprint(\"Agora eu sei editar e executar um Jupyter Notebook!\")\nVocê pode inserir novas células escolhendo na barra de menu o tipo de célula (Code para código ou Markdown para texto) e clicando no botão +. Você também pode fazer isso clicando em Insert no menu superior.\n\n\n\nOs notebooks jupyter também podem ser executados diretamente de alguma IDE que dê suporte para ele, como VS Code (com a extensão Python) e PyCharm. Para isso vocês devem ter instalado o Python e o Jupyter Notebook anteriormente.\nTeste executar o notebook em sua IDE favorita (durante a disciplina usarei o VS Code para demonstrações).\n\n\n\n\nVocê também pode rodar o notebook em algum serviço da nuvem gratuito como o Google Colab. Para isso, acesse em seu browser o endereço https://colab.research.google.com.\n\n\n\n\n\n\nAtenção\n\n\n\nO ideal é estar logado com a sua conta Google do domínio @dcx.ufpb.br para usar o Google Notebook.\n\n\nAo abrir o Colab, você pode fazer o upload do arquivo notebook (.ipynb) que deseja executar. Uma forma ainda mais fácil é criar um notebook usando a opção GitHub, inserindo o link do repositório do livro https://github.com/wesm/pydata-book, escolhendo a ramificação (branch) 3rd-edition e clicando no nome do arquivo ch02.ipynb para abrí-lo, como na imagem abaixo:\n\nCom isso, você terá um ambiente de execução do notebook que pode ser editado e executado de forma similar ao ambiente Jupyter, mas que irá rodar na nuvem da Google e poderá ser compartilhado facilmente com outras pessoas. A tela de edição do notebook no Colab é mostrada abaixo:\n\n\n\n\nO GitHub também criou um ambiente de desenvolvimento e execução de código na própria plataforma, chamada GitHub Codespaces, que abre no browser uma IDE similar ao VS Code onde você também consegue executar notebooks Jupyter.\nPara criar um Codespace para o notebook da atividade, entre na página do repositório no GitHub, escolha a branch correta (3rd-edition), clique no botão Code e em seguida em Create codespace on 3rd-edition, conforme a imagem abaixo.\n\n\n\n\n\n\n\nDica\n\n\n\nVocê também pode criar um Codespace apertando a tecla . do teclado na página do repositório e da branch que você deseja.\n\n\n\n\n\nPara fazer outro teste dos passos feitos anteriormente e também fazer uma revisão de estruturas de dados, funções e arquivos em Python, você deve seguir o passo a passo do notebook do capítulo 3, lendo e executando os blocos do notebook.\nEscolha o ambiente de execução mais adequado para você (Jupyter, IDE ou Colab) e faça novamente os passos anteriores, agora com o arquivo ch03.ipynb do repositório.\n\n\n\n\nMcKinney, Wes. Python for Data Analysis(3rd Edition). O’Reilly Media, 2022."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de Dados I @ DCX / CCAE / UFPB",
    "section": "",
    "text": "Material da disciplina de Análise de Dados I"
  },
  {
    "objectID": "index.html#aulas",
    "href": "index.html#aulas",
    "title": "Análise de Dados I @ DCX / CCAE / UFPB",
    "section": "Aulas",
    "text": "Aulas\n\nApresentação da disciplina (Slides)\n\n\nIntrodução\n\n1.1 Introdução à análise de dados (Slides)\n1.2 Introdução ao Python e Jupyter Notebook (Atividade)\n1.3 Introdução ao Pandas (Notebook)\n1.4 Exemplo com Pandas: análise de notas (Notebook)"
  },
  {
    "objectID": "1-introducao/3-intro-pandas.html",
    "href": "1-introducao/3-intro-pandas.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Referências\n\nPython for Data Analysis - 5 Getting Started with pandas"
  },
  {
    "objectID": "1-introducao/4-exemplo-pandas.html",
    "href": "1-introducao/4-exemplo-pandas.html",
    "title": "Aulas AD 1",
    "section": "",
    "text": "Vamos usar um exemplo de análise para demonstrar mais funções da biblioteca Pandas de Python.\n\n\nO primeiro passo será carregar os dados que estão armazenados em um arquivo CSV. O arquivo que possui as notas das 4 unidades da disciplina Sistemas Operacionais no período 2017.1. O parâmetro index_col=\"id\" indica que a coluna id que consta no arquivo será o identificar das linhas do DataFrame.\n\nimport numpy as np\nimport pandas as pd\n\nso_20171 = pd.read_csv(\"../dados/notas_so_20171.csv\")\nso_20171\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n    \n    \n      5\n      6\n      9.6\n      9.8\n      10.0\n      9.0\n    \n    \n      6\n      7\n      9.0\n      8.5\n      8.5\n      8.0\n    \n    \n      7\n      8\n      4.0\n      7.5\n      5.3\n      2.0\n    \n    \n      8\n      9\n      10.0\n      9.9\n      9.6\n      9.1\n    \n    \n      9\n      10\n      8.3\n      8.7\n      8.0\n      6.7\n    \n    \n      10\n      11\n      10.0\n      10.0\n      8.5\n      9.8\n    \n    \n      11\n      12\n      7.3\n      9.0\n      7.8\n      7.0\n    \n    \n      12\n      13\n      8.8\n      9.2\n      10.0\n      8.7\n    \n    \n      13\n      14\n      6.5\n      8.6\n      7.0\n      4.0\n    \n    \n      14\n      15\n      10.0\n      8.5\n      8.1\n      8.5\n    \n    \n      15\n      16\n      9.7\n      10.0\n      7.7\n      7.5\n    \n    \n      16\n      17\n      8.3\n      9.7\n      8.7\n      6.8\n    \n    \n      17\n      18\n      7.5\n      9.4\n      6.0\n      7.2\n    \n    \n      18\n      19\n      9.3\n      9.9\n      9.8\n      9.1\n    \n    \n      19\n      20\n      0.0\n      2.5\n      1.0\n      0.0\n    \n    \n      20\n      21\n      5.0\n      8.0\n      5.8\n      4.8\n    \n  \n\n\n\n\nPodemos usar o comando info() para obter informações sobre os tipos das colunas e a presença de dados nulos:\n\nso_20171.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21 entries, 0 to 20\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   id      21 non-null     int64  \n 1   nota_1  21 non-null     float64\n 2   nota_2  21 non-null     float64\n 3   nota_3  21 non-null     float64\n 4   nota_4  21 non-null     float64\ndtypes: float64(4), int64(1)\nmemory usage: 968.0 bytes\n\n\nOutra função útil é a describe(), que calcula estatísticas básicas para as colunas de um DataFrame:\n\nso_20171.describe()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      count\n      21.000000\n      21.000000\n      21.000000\n      21.000000\n      21.000000\n    \n    \n      mean\n      11.000000\n      7.595238\n      8.438095\n      7.771429\n      6.742857\n    \n    \n      std\n      6.204837\n      2.408003\n      2.020266\n      2.242129\n      2.510492\n    \n    \n      min\n      1.000000\n      0.000000\n      2.500000\n      1.000000\n      0.000000\n    \n    \n      25%\n      6.000000\n      7.000000\n      8.000000\n      7.000000\n      5.100000\n    \n    \n      50%\n      11.000000\n      8.300000\n      9.000000\n      8.100000\n      7.200000\n    \n    \n      75%\n      16.000000\n      9.300000\n      9.800000\n      9.600000\n      8.700000\n    \n    \n      max\n      21.000000\n      10.000000\n      10.000000\n      10.000000\n      9.800000\n    \n  \n\n\n\n\nJá vimos que para calcular a média das notas de cada unidade podemos fazer:\n\nso_20171.mean(numeric_only=True)\n\nid        11.000000\nnota_1     7.595238\nnota_2     8.438095\nnota_3     7.771429\nnota_4     6.742857\ndtype: float64\n\n\nSuponha que queremos calcular a média das notas de cada uma das 4 unidades para todas as turmas de SO nos últimos 10 períodos. Para fazer do modo acima, precisaríamos de pelo menos 10 linhas de código, uma para cada turma. Isso não parece muito interessante. O jeito mais eficiente de fazer isso é juntar todos os dados em uma única tabela e aplicar funções em grupos de dados.\nVamos fazer um exemplo carregando os dados de mais um período (2017.2):\n\nso_20172 = pd.read_csv(\"../dados/notas_so_20172.csv\")\nso_20172\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n  \n  \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n    \n    \n      5\n      6\n      6.6\n      6.7\n      7.2\n      3.8\n    \n    \n      6\n      7\n      9.3\n      9.0\n      9.2\n      8.5\n    \n    \n      7\n      8\n      9.0\n      10.0\n      8.7\n      8.1\n    \n    \n      8\n      9\n      7.8\n      8.5\n      9.0\n      7.5\n    \n    \n      9\n      10\n      7.5\n      8.0\n      9.0\n      5.3\n    \n    \n      10\n      11\n      8.3\n      9.0\n      5.2\n      6.2\n    \n    \n      11\n      12\n      7.5\n      9.8\n      8.2\n      6.0\n    \n    \n      12\n      13\n      7.7\n      7.3\n      4.5\n      6.5\n    \n    \n      13\n      14\n      5.8\n      7.5\n      6.5\n      6.2\n    \n    \n      14\n      15\n      7.8\n      9.3\n      8.8\n      4.5\n    \n    \n      15\n      16\n      0.0\n      2.5\n      2.0\n      3.5\n    \n    \n      16\n      17\n      5.8\n      8.3\n      7.5\n      3.5\n    \n    \n      17\n      18\n      9.6\n      9.0\n      10.0\n      5.5\n    \n    \n      18\n      19\n      7.0\n      6.7\n      6.6\n      8.0\n    \n    \n      19\n      20\n      7.3\n      8.6\n      7.3\n      0.0\n    \n    \n      20\n      21\n      9.5\n      8.8\n      7.8\n      6.2\n    \n    \n      21\n      22\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      22\n      23\n      7.3\n      8.0\n      6.7\n      7.5\n    \n    \n      23\n      24\n      9.5\n      8.8\n      7.0\n      8.3\n    \n    \n      24\n      25\n      9.7\n      9.0\n      3.4\n      7.4\n    \n    \n      25\n      26\n      8.9\n      6.7\n      5.5\n      4.5\n    \n  \n\n\n\n\n\n\n\nNote que a sua estrutura é semelhante à do DataFrame anterior. Desta forma, podemos juntá-los em um único data frame. Antes disso, temos que adicionar uma nova coluna que identifique o período que as notas se referem:\n\nso_20171[\"periodo\"] = \"2017.1\"\nso_20171.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n      2017.1\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n      2017.1\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n      2017.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n      2017.1\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n      2017.1\n    \n  \n\n\n\n\n\nso_20172[\"periodo\"] = \"2017.2\"\nso_20172.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n      2017.2\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n      2017.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n      2017.2\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n      2017.2\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n      2017.2\n    \n  \n\n\n\n\nO comando head() mostra apenas as primeiras linhas da tabela.\nComo os dois DataFrames possuem as mesmas colunas, podemos juntá-los com a função concat:\n\nso = pd.concat([so_20171, so_20172])\nso\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n      periodo\n    \n  \n  \n    \n      0\n      1\n      8.3\n      8.0\n      9.3\n      8.0\n      2017.1\n    \n    \n      1\n      2\n      7.0\n      7.7\n      4.6\n      8.7\n      2017.1\n    \n    \n      2\n      3\n      7.8\n      3.2\n      7.7\n      5.1\n      2017.1\n    \n    \n      3\n      4\n      7.3\n      9.3\n      9.8\n      4.8\n      2017.1\n    \n    \n      4\n      5\n      5.8\n      9.8\n      10.0\n      6.8\n      2017.1\n    \n    \n      5\n      6\n      9.6\n      9.8\n      10.0\n      9.0\n      2017.1\n    \n    \n      6\n      7\n      9.0\n      8.5\n      8.5\n      8.0\n      2017.1\n    \n    \n      7\n      8\n      4.0\n      7.5\n      5.3\n      2.0\n      2017.1\n    \n    \n      8\n      9\n      10.0\n      9.9\n      9.6\n      9.1\n      2017.1\n    \n    \n      9\n      10\n      8.3\n      8.7\n      8.0\n      6.7\n      2017.1\n    \n    \n      10\n      11\n      10.0\n      10.0\n      8.5\n      9.8\n      2017.1\n    \n    \n      11\n      12\n      7.3\n      9.0\n      7.8\n      7.0\n      2017.1\n    \n    \n      12\n      13\n      8.8\n      9.2\n      10.0\n      8.7\n      2017.1\n    \n    \n      13\n      14\n      6.5\n      8.6\n      7.0\n      4.0\n      2017.1\n    \n    \n      14\n      15\n      10.0\n      8.5\n      8.1\n      8.5\n      2017.1\n    \n    \n      15\n      16\n      9.7\n      10.0\n      7.7\n      7.5\n      2017.1\n    \n    \n      16\n      17\n      8.3\n      9.7\n      8.7\n      6.8\n      2017.1\n    \n    \n      17\n      18\n      7.5\n      9.4\n      6.0\n      7.2\n      2017.1\n    \n    \n      18\n      19\n      9.3\n      9.9\n      9.8\n      9.1\n      2017.1\n    \n    \n      19\n      20\n      0.0\n      2.5\n      1.0\n      0.0\n      2017.1\n    \n    \n      20\n      21\n      5.0\n      8.0\n      5.8\n      4.8\n      2017.1\n    \n    \n      0\n      1\n      9.8\n      9.7\n      9.5\n      7.0\n      2017.2\n    \n    \n      1\n      2\n      9.2\n      9.8\n      7.0\n      7.2\n      2017.2\n    \n    \n      2\n      3\n      9.1\n      8.0\n      9.5\n      8.0\n      2017.2\n    \n    \n      3\n      4\n      5.6\n      7.8\n      8.5\n      6.5\n      2017.2\n    \n    \n      4\n      5\n      6.3\n      8.0\n      6.3\n      5.5\n      2017.2\n    \n    \n      5\n      6\n      6.6\n      6.7\n      7.2\n      3.8\n      2017.2\n    \n    \n      6\n      7\n      9.3\n      9.0\n      9.2\n      8.5\n      2017.2\n    \n    \n      7\n      8\n      9.0\n      10.0\n      8.7\n      8.1\n      2017.2\n    \n    \n      8\n      9\n      7.8\n      8.5\n      9.0\n      7.5\n      2017.2\n    \n    \n      9\n      10\n      7.5\n      8.0\n      9.0\n      5.3\n      2017.2\n    \n    \n      10\n      11\n      8.3\n      9.0\n      5.2\n      6.2\n      2017.2\n    \n    \n      11\n      12\n      7.5\n      9.8\n      8.2\n      6.0\n      2017.2\n    \n    \n      12\n      13\n      7.7\n      7.3\n      4.5\n      6.5\n      2017.2\n    \n    \n      13\n      14\n      5.8\n      7.5\n      6.5\n      6.2\n      2017.2\n    \n    \n      14\n      15\n      7.8\n      9.3\n      8.8\n      4.5\n      2017.2\n    \n    \n      15\n      16\n      0.0\n      2.5\n      2.0\n      3.5\n      2017.2\n    \n    \n      16\n      17\n      5.8\n      8.3\n      7.5\n      3.5\n      2017.2\n    \n    \n      17\n      18\n      9.6\n      9.0\n      10.0\n      5.5\n      2017.2\n    \n    \n      18\n      19\n      7.0\n      6.7\n      6.6\n      8.0\n      2017.2\n    \n    \n      19\n      20\n      7.3\n      8.6\n      7.3\n      0.0\n      2017.2\n    \n    \n      20\n      21\n      9.5\n      8.8\n      7.8\n      6.2\n      2017.2\n    \n    \n      21\n      22\n      2.0\n      0.0\n      1.0\n      2.0\n      2017.2\n    \n    \n      22\n      23\n      7.3\n      8.0\n      6.7\n      7.5\n      2017.2\n    \n    \n      23\n      24\n      9.5\n      8.8\n      7.0\n      8.3\n      2017.2\n    \n    \n      24\n      25\n      9.7\n      9.0\n      3.4\n      7.4\n      2017.2\n    \n    \n      25\n      26\n      8.9\n      6.7\n      5.5\n      4.5\n      2017.2\n    \n  \n\n\n\n\nE se quisermos saber as médias de cada período específico, usando a tabela com todas as notas? Vamos mostrar duas formas de fazer isso.\n\n\n\nPodemos filtrar os dados de cada período e em seguida calcular a média da unidade 1:\n\nso[so[\"periodo\"] == \"2017.1\"][\"nota_1\"].mean()\n\n7.595238095238097\n\n\n\nso[so[\"periodo\"] == \"2017.2\"][\"nota_1\"].mean()\n\n7.457692307692308\n\n\nDa mesma forma, podemos ver a fração de alunos com nota acima da média na unidade 1:\n\nlen(so[(so[\"periodo\"] == \"2017.1\") & (so[\"nota_1\"] >= 7)].index) / len(so[(so[\"periodo\"] == \"2017.1\")].index)\n\n0.7619047619047619\n\n\n\n len(so[(so[\"periodo\"] == \"2017.2\") & (so[\"nota_1\"] >= 7)].index) / len(so[(so[\"periodo\"] == \"2017.2\")].index)\n\n0.7307692307692307\n\n\nExiste uma forma mais adequada para fazer esse tipo de cálculo agrupado por categoria.\n\n\n\nA função groupby agrupa os dados de acordo com categorias definidas pelas colunas e aplica funções para cada grupo. A função summarise aplica uma função para cada grupo de dados, gerando novas colunas no data frame.\nVamos usar como exemplo o cálculo da média para cada unidade, agrupado por período:\n\nso_media = so.groupby([\"periodo\"]).mean()\nso_media\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      nota_4\n    \n    \n      periodo\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2017.1\n      11.0\n      7.595238\n      8.438095\n      7.771429\n      6.742857\n    \n    \n      2017.2\n      13.5\n      7.457692\n      7.876923\n      6.996154\n      5.892308\n    \n  \n\n\n\n\nComo fazemos então para calcular a fração de aprovados na unidade 1 para cada período?\n\ndef prop_aprovados(df, col=\"nota_1\", nota_aprovacao=7):\n    return len(df[df[\"nota_1\"] >= nota_aprovacao].index) / len(df.index)\n    \nso.groupby([\"periodo\"]).apply(prop_aprovados)\n\nperiodo\n2017.1    0.761905\n2017.2    0.730769\ndtype: float64\n\n\nAinda temos um incoveniente: ainda precisamos fazer cálculos especificando cada unidade que pretendemos observar. Além disso, se em algum dos períodos tivermos disciplinas com uma quantidade diferente de unidades (3 ao invés de 4) teríamos problemas com a estrutura atual. Vamos ver a seguir como organizar os dados de uma forma ainda mais adequada.\n\n\n\nVamos carregar os dados de outras duas disciplinas, Sistemas Distribuídos e Avaliação de Desempenho, aproveitando para adicionar o nome da disciplina e o período no data frame:\n\nads_20171 = pd.read_csv(\"../dados/notas_ads_20171.csv\")\nads_20171[\"disciplina\"] = \"Avaliação de Desempenho de Sistemas\"\nads_20171[\"periodo\"] = \"2017.1\"\nads_20171.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      disciplina\n      periodo\n    \n  \n  \n    \n      0\n      1\n      9.8\n      7.0\n      5.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      1\n      2\n      8.8\n      9.7\n      3.5\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      2\n      3\n      9.5\n      7.0\n      8.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      3\n      4\n      7.0\n      9.8\n      9.8\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n    \n      4\n      5\n      3.5\n      8.8\n      9.0\n      Avaliação de Desempenho de Sistemas\n      2017.1\n    \n  \n\n\n\n\n\nsd_20172 = pd.read_csv(\"../dados/notas_sd_20172.csv\")\nsd_20172[\"disciplina\"] = \"Sistemas Distribuidos\"\nsd_20172[\"periodo\"] = \"2017.2\"\nsd_20172.head()\n\n\n\n\n\n  \n    \n      \n      id\n      nota_1\n      nota_2\n      nota_3\n      disciplina\n      periodo\n    \n  \n  \n    \n      0\n      1\n      6.8\n      8.0\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      1\n      2\n      4.2\n      3.0\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      2\n      3\n      0.0\n      0.0\n      0.0\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      3\n      4\n      8.0\n      7.5\n      9.5\n      Sistemas Distribuidos\n      2017.2\n    \n    \n      4\n      5\n      7.0\n      7.5\n      10.0\n      Sistemas Distribuidos\n      2017.2\n    \n  \n\n\n\n\nPodemos juntar as notas de todas as disciplinas para facilitar o processamento. Mas temos um problema: as disciplinas de SO têm notas de 4 unidades, enquanto as de ADS e SD só têm 3 unidades. Além disso, ter uma coluna na tabela para cada unidade nos força a ter que especificar para qual unidade queremos calcular estatísticas. E se uma disciplina tiver 10 unidades (mini-testes, por exemplo), temos que ter 10 cálculos para calcular as médias de cada unidade?\nAi que entra o tidy data, que é uma forma de organizar os dados que facilita muito a análise usando as ferramentas de análise de dados.\nExistem 3 regras para uma tabela ser tidy:\n\nCada variável deve ter sua própria coluna.\nCada observação deve ter sua própria linha.\nCada valor deve ter sua própria célula.\n\nA figura abaixo mostra essas regras visualmente:\n\nComo transformar então nossas tabelas de notas no formato tidy? Um dos problems atuais é que a variável nota está espalhada em várias colunas: nota_1, nota_2, nota_3, … Temos outra variável implícita que está misturada com a variável nota que é a variável unidade, que pode indicar a qual unidade uma prova se refere. Desta forma, a tabela no formato tidy poderia ter uma coluna para a variável unidade e ter apenas uma coluna para a variável nota.\nVamos usar o Pandas para transformar os dados no formato tidy, usando funções de reshaping e pivot tables (leia este tutorial do Pandas para entender mais).\nPrimeiro para as notas de Sistemas Operacionais, vamos adicionar uma coluna com o nome da disciplina e transformar as colunas nota_1, nota_2, nota_3 e nota_4 em duas colunas: unidade e nota. Ou seja, um aluno da turma ao invés de ter as 4 notas em apenas uma linha, ele terá as notas distribuídas em 4 linhas, uma para cada unidade. Para isto, vamos usar a função do Pandas wide_to_long:\n\nso[\"disciplina\"] = \"Sistemas Operacionais\"\nso_tidy = pd.wide_to_long(so, stubnames='nota', i=['id', 'periodo', 'disciplina'],\n                          j='unidade', sep=\"_\")\nso_tidy\n\n\n\n\n\n  \n    \n      \n      \n      \n      \n      nota\n    \n    \n      id\n      periodo\n      disciplina\n      unidade\n      \n    \n  \n  \n    \n      1\n      2017.1\n      Sistemas Operacionais\n      1\n      8.3\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.3\n    \n    \n      4\n      8.0\n    \n    \n      2\n      2017.1\n      Sistemas Operacionais\n      1\n      7.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      25\n      2017.2\n      Sistemas Operacionais\n      4\n      7.4\n    \n    \n      26\n      2017.2\n      Sistemas Operacionais\n      1\n      8.9\n    \n    \n      2\n      6.7\n    \n    \n      3\n      5.5\n    \n    \n      4\n      4.5\n    \n  \n\n188 rows × 1 columns\n\n\n\nO parâmetro stubname='nota' indica que ele vai transformar as colunas que começam com a palavra “nota”. O parâmetro i=['id', 'periodo', 'disciplina'] indica as colunas que identificarão unicamente cada linha de observação (serão os índices). E o parâmetro j='unidade' indica o nome da nova coluna que será criada, onde os valores serão os números encontrados nas colunas nota_X, considerando que sep=\"_\" e os nomes das colunas têm o formato nota_unidade.\nFazendo isso agora para as outras disciplinas e concatenando tudo em um único DataFrame. Vamos também renomear o index id para id_aluno para melhor compreensão dos dados. O parâmetro inplace=True faz com que o DataFrame notas seja alterado ao invés de retornar um novo DataFrame com a alteração realizada.\n\nads_tidy = pd.wide_to_long(ads_20171, stubnames='nota', i=['id', 'periodo', 'disciplina'], j='unidade', sep=\"_\")\nsd_tidy = pd.wide_to_long(sd_20172, stubnames='nota', i=['id', 'periodo', 'disciplina'], j='unidade', sep=\"_\")\n\nnotas = pd.concat([so_tidy, ads_tidy, sd_tidy])\nnotas.index.set_names({'id': 'id_aluno'}, inplace=True)\n        \nnotas\n\n\n\n\n\n  \n    \n      \n      \n      \n      \n      nota\n    \n    \n      id_aluno\n      periodo\n      disciplina\n      unidade\n      \n    \n  \n  \n    \n      1\n      2017.1\n      Sistemas Operacionais\n      1\n      8.3\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.3\n    \n    \n      4\n      8.0\n    \n    \n      2\n      2017.1\n      Sistemas Operacionais\n      1\n      7.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23\n      2017.2\n      Sistemas Distribuidos\n      2\n      9.7\n    \n    \n      3\n      10.0\n    \n    \n      24\n      2017.2\n      Sistemas Distribuidos\n      1\n      9.8\n    \n    \n      2\n      8.0\n    \n    \n      3\n      9.5\n    \n  \n\n344 rows × 1 columns\n\n\n\nComo calcular agora a nota média para cada disciplina, período e unidade? Ficou bem mais fácil.\n\n\n\nnotas.groupby([\"disciplina\", \"periodo\", \"unidade\"]).mean()\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      unidade\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.939286\n    \n    \n      2\n      8.382143\n    \n    \n      3\n      7.425000\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      1\n      7.441667\n    \n    \n      2\n      6.729167\n    \n    \n      3\n      8.895833\n    \n    \n      Sistemas Operacionais\n      2017.1\n      1\n      7.595238\n    \n    \n      2\n      8.438095\n    \n    \n      3\n      7.771429\n    \n    \n      4\n      6.742857\n    \n    \n      2017.2\n      1\n      7.457692\n    \n    \n      2\n      7.876923\n    \n    \n      3\n      6.996154\n    \n    \n      4\n      5.892308\n    \n  \n\n\n\n\n\n\n\n\nmedia_alunos = notas.groupby([\"disciplina\", \"periodo\", \"id_aluno\"]).mean()\nmedia_alunos\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.266667\n    \n    \n      2\n      7.333333\n    \n    \n      3\n      8.166667\n    \n    \n      4\n      8.866667\n    \n    \n      5\n      7.100000\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n    \n    \n      23\n      7.375000\n    \n    \n      24\n      8.400000\n    \n    \n      25\n      7.375000\n    \n    \n      26\n      6.400000\n    \n  \n\n99 rows × 1 columns\n\n\n\n\n\n\n\nmedia_turma = media_alunos.groupby([\"disciplina\", \"periodo\"]).mean()\nmedia_turma\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      7.915476\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      7.688889\n    \n    \n      Sistemas Operacionais\n      2017.1\n      7.636905\n    \n    \n      2017.2\n      7.055769\n    \n  \n\n\n\n\n\n\n\nE se eu quiser calcular outras estatísticas como a quantidade de alunos, nota mínima, mediana, média e máxima? Podemos usar a função agg para aplicar várias funções de agregação nos dados.\n\ndef prop_aprovados(medias, min_media_aprovacao=5):\n    return medias[medias >= min_media_aprovacao].count() / medias.count()\n\n(\n    media_alunos\n    .groupby([\"disciplina\", \"periodo\"])\n    .agg(['count', 'min', 'median', 'mean', 'max', prop_aprovados])\n)\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      \n      \n      count\n      min\n      median\n      mean\n      max\n      prop_aprovados\n    \n    \n      disciplina\n      periodo\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      28\n      0.000\n      8.266667\n      7.915476\n      10.00\n      0.892857\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      24\n      0.000\n      8.250000\n      7.688889\n      10.00\n      0.916667\n    \n    \n      Sistemas Operacionais\n      2017.1\n      21\n      0.875\n      8.100000\n      7.636905\n      9.65\n      0.904762\n    \n    \n      2017.2\n      26\n      1.250\n      7.375000\n      7.055769\n      9.00\n      0.923077\n    \n  \n\n\n\n\nVocê também pode aplicar uma função própria, por exemplo a que calcula a proporção de alunos aprovados em cada disciplina, que conta as linhas apenas de alunos com nota maior ou igual à 5 e divide pela quantidade total de alunos dentro do grupo:\n\ndef prop_aprovados(medias, min_media_aprovacao=5):\n    return medias[medias >= min_media_aprovacao].count() / medias.count()\n\n(\n    media_alunos\n    .groupby([\"disciplina\", \"periodo\"])\n    .agg([prop_aprovados])\n\"APROVADO\" if media_alunos[\"nota\"] >= 5 else \"REPROVADO\")\n\nSyntaxError: invalid syntax (2677895194.py, line 8)\n\n\n\n\n\nVamos adicionar uma coluna na tabela indicando se o aluno foi aprovado por média ou não. Para isso, vamos criar a nova função e aplicá-la para cada linha do dataframe com a função apply:\n\ndef calcula_resultado(media):\n    return 'APROVADO' if media >= 5 else 'REPROVADO'\n\nmedia_alunos[\"resultado\"] = media_alunos[\"nota\"].apply(calcula_resultado)\nmedia_alunos\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n      resultado\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      1\n      7.266667\n      APROVADO\n    \n    \n      2\n      7.333333\n      APROVADO\n    \n    \n      3\n      8.166667\n      APROVADO\n    \n    \n      4\n      8.866667\n      APROVADO\n    \n    \n      5\n      7.100000\n      APROVADO\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n      REPROVADO\n    \n    \n      23\n      7.375000\n      APROVADO\n    \n    \n      24\n      8.400000\n      APROVADO\n    \n    \n      25\n      7.375000\n      APROVADO\n    \n    \n      26\n      6.400000\n      APROVADO\n    \n  \n\n99 rows × 2 columns\n\n\n\n\n\n\nA função sort_values ordena o dataframe com base nos valores de uma ou mais colunas. O parâmetro ascending=False é usado para indicar que a ordenação não será feita na ordem padrão ascendente (ou seja, será na ordem descendente do maior para o menor valor).\n\nmedia_alunos.sort_values('nota', ascending=False)\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n      resultado\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      9\n      10.000000\n      APROVADO\n    \n    \n      10\n      10.000000\n      APROVADO\n    \n    \n      23\n      10.000000\n      APROVADO\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      12\n      10.000000\n      APROVADO\n    \n    \n      9\n      9.933333\n      APROVADO\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      Sistemas Operacionais\n      2017.2\n      22\n      1.250000\n      REPROVADO\n    \n    \n      2017.1\n      20\n      0.875000\n      REPROVADO\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      8\n      0.666667\n      REPROVADO\n    \n    \n      3\n      0.000000\n      REPROVADO\n    \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      20\n      0.000000\n      REPROVADO\n    \n  \n\n99 rows × 2 columns\n\n\n\n\n\n\nPega o dataframe com a média dos alunos, ordena pela média em ordem decrescente, agrupa por turma (disciplina e período) e pega as 3 primeiras linhas de cada grupo.\n\n(\n    media_alunos\n    .sort_values('nota', ascending=False)\n    .groupby(['disciplina', 'periodo'])\n    .head(3)\n)\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      9\n      10.000000\n    \n    \n      10\n      10.000000\n    \n    \n      23\n      10.000000\n    \n    \n      Sistemas Distribuidos\n      2017.2\n      12\n      10.000000\n    \n    \n      9\n      9.933333\n    \n    \n      23\n      9.900000\n    \n    \n      Sistemas Operacionais\n      2017.1\n      9\n      9.650000\n    \n    \n      6\n      9.600000\n    \n    \n      11\n      9.575000\n    \n    \n      2017.2\n      1\n      9.000000\n    \n    \n      7\n      9.000000\n    \n    \n      8\n      8.950000\n    \n  \n\n\n\n\nNote que organizamos a sequência de comandos com uma função por linha. Essa forma fica mais legível quando se tem muitos comandos seguidos. Como cada função retorna um dataframe, dá para encadear chamadas de funções dessa forma no Pandas. Para funcionar com um comando por linha é preciso colocar a sequência de funções entre parênteses.\n\n\n\n\nOutra utilidade do Pandas é pegar apenas “fatias” (slices) dos dados, seja filtrando linhas ou colunas. O pandas oferece a função .loc para fazer o slicing a partir dos índices e a função .iloc para filtrar com base no número da linha.\nPor exemplo, para pegar apenas as linhas que tem “Sistemas Operacionais” como primeiro índice (disciplina), podemos usar:\n\nmedia_alunos.loc[\"Sistemas Distribuidos\"]\n\n\n\n\n\n  \n    \n      \n      \n      nota\n    \n    \n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      2017.2\n      1\n      8.100000\n    \n    \n      2\n      5.566667\n    \n    \n      3\n      0.000000\n    \n    \n      4\n      8.333333\n    \n    \n      5\n      8.166667\n    \n    \n      6\n      9.533333\n    \n    \n      7\n      8.433333\n    \n    \n      8\n      0.666667\n    \n    \n      9\n      9.933333\n    \n    \n      10\n      6.266667\n    \n    \n      11\n      9.700000\n    \n    \n      12\n      10.000000\n    \n    \n      13\n      7.666667\n    \n    \n      14\n      6.033333\n    \n    \n      15\n      9.133333\n    \n    \n      16\n      7.266667\n    \n    \n      17\n      8.833333\n    \n    \n      18\n      7.566667\n    \n    \n      19\n      8.766667\n    \n    \n      20\n      9.833333\n    \n    \n      21\n      7.933333\n    \n    \n      22\n      7.800000\n    \n    \n      23\n      9.900000\n    \n    \n      24\n      9.100000\n    \n  \n\n\n\n\nE se quisermos pegar apenas as linhas 5 a 10 do DataFrame podemos usar:\n\nmedia_alunos.iloc[5:10]\n\n\n\n\n\n  \n    \n      \n      \n      \n      nota\n    \n    \n      disciplina\n      periodo\n      id_aluno\n      \n    \n  \n  \n    \n      Avaliação de Desempenho de Sistemas\n      2017.1\n      6\n      8.200000\n    \n    \n      7\n      9.933333\n    \n    \n      8\n      3.766667\n    \n    \n      9\n      10.000000\n    \n    \n      10\n      10.000000\n    \n  \n\n\n\n\nPodemos também fazer um slice de linha e coluna ao mesmo tempo. Por exemplo, para filtrar as linhas com índices de 0 a 4 e a coluna nota_3, podemos fazer:\n\nso.loc[0:4, \"nota_3\"]\n\n0     9.3\n1     4.6\n2     7.7\n3     9.8\n4    10.0\nName: nota_3, dtype: float64\n\n\nOu para pegar o valor que está na linha 10 e coluna 3 (lembrando que Python indexa a partir do 0):\n\nso.iloc[10, 3]\n\n8.5\n\n\n\n\n\nTambém podemos exportar um dataframe pra um arquivo. Por exemplo, para exportar a tabela de média dos alunos para um arquivo podemos rodar:\nmedia_alunos.to_csv(\"../dados/notas_medias_alunos.csv\")"
  }
]