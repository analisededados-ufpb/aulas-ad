---
title: "Análise de dados"
subtitle: "Regressão linear múltipla"
author: "Prof. Marcus Carvalho @ DCX / CCAE / UFPB"
format:
    revealjs:
        slide-number: true
        chalkboard: true
        incremental: false
        theme: [simple, ../custom.scss]
        echo: true
---

```{python}
#| include: false

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from pathlib import Path
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import OLSInfluence

DATA_DIR = Path().resolve().parent / 'dados'
HOUSE_CSV = DATA_DIR / 'house_sales.csv'
```

## Regressão linear múltipla

- Estima o valor de uma variável resposta $y$ em função de $k$ variáveis preditoras $(x_1, ..., x_k)$ com base em uma relação linear:

$$y = b_0 + b_1 x_1 + b_2 x_2 + ... + b_k x_k + e$$

- Onde:
    - $(b_0, ..., b_k)$ são os $k+1$ parâmetros da regressão
    - $e$ representa o erro do modelo

## Exemplo de regressão múltipla: preço de casas

- O governo precisa estimar o preço de casas para cobrar impostos
- Podemos estimar o preço de uma casa (`AdjSalePrice`) com base em outras variáveis: área (`SqFtTotLiving`), banheiros (`Bathrooms`), quartos (`Bedrooms`), nível (`BldgGrade`)

```{python}
#| echo: false
subset = ['AdjSalePrice', 'SqFtTotLiving', 'SqFtLot', 'Bathrooms', 
          'Bedrooms', 'BldgGrade']
house = pd.read_csv(HOUSE_CSV, sep='\t')
house[subset].head(5)
```

## Exemplo de regressão múltipla: preço de casas

- Aplicando e avaliando o modelo de regressão com `scikit-learn`

:::: {.columns}
:::{.column}
```{python}
predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms',
              'Bedrooms', 'BldgGrade']
outcome = 'AdjSalePrice'

house_lm = LinearRegression()
house_lm.fit(house[predictors], house[outcome])

print(f'Intercept: {house_lm.intercept_:.3f}')
print('Coefficients:')
for name, coef in zip(predictors, house_lm.coef_):
    print(f' {name}: {coef}')
```
:::
::: {.column}
```{python}
fitted = house_lm.predict(house[predictors])
RMSE = np.sqrt(mean_squared_error(house[outcome], fitted))
r2 = r2_score(house[outcome], fitted)
print(f'Root Mean Square Error (RMSE): {RMSE:.0f}')
print(f'Coefficiente of determination (r2): {r2:.4f}')
```
:::
::::


## Exemplo de regressão múltipla: preço de casas

- Avaliando o modelo de regressão linear com o `statsmodels`

```{python}
model = sm.OLS(house[outcome], house[predictors].assign(const=1))
results = model.fit()
print(results.summary())
```


## Interpretando resultados da regressão múltipla

- Os coeficientes das variáveis preditoras têm o mesmo significado da regressão simples
    - Indica quanto a variável resposta muda para cada unidade da variável preditora correspondente

- _Root mean squared error_, raíz da média dos erros ao quadrado, é uma métrica útil para comparar a qualidade de diferentes modelos

$$RMSE = \sqrt{\frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{n}}$$

## Interpretando resultados da regressão múltipla

- Além do `R-squared` ($R^2$), algumas ferramentas como o `statsmodels` também reportam outras métricas:
    - `Adjusted R-squared` penaliza modelos com muitos preditores
        - `AIC` e `BIC` são métricas que também penalizam a adição de variáveis
    - O _Teste-t_ é usado para medir a importância de cada preditor
        - _p-valor_ da estatística `t` (`P>|t|`) indica significância estatística de preditor
        - Quanto maior o `t` e menor seu _p-valor_, mais significativo é o preditor
    - O _Teste-F_ verifica se a regressão é significativa ($SSR > SSE$)
    - No geral, p-valores $< 0.05$ indicam significância estatística
        - Veremos sobre testes de hipótese e p-valor mais para frente

## Variáveis preditoras não numéricas

- Deve-se converter variáveis categóricas e _boolean_ em númericas

::: {.smaller-table}
```{python}
#| echo: false
predictors2 = ['PropertyType', 'NbrLivingUnits', 'SqFtFinBasement',
               'YrBuilt', 'YrRenovated', 'NewConstruction']
predictors_full = predictors + predictors2
house.filter(predictors2).head()
```
:::

- Variáveis _dummy_: cada categoria vira uma coluna, com valor 0 ou 1

::: {.smaller-table}
```{python}
X = pd.get_dummies(house[predictors_full], drop_first=True)
X['NewConstruction'] = [1 if nc else 0 for nc in X['NewConstruction']]
```

```{python}
#| echo: false
X.drop(columns=predictors).head()
```
:::

## Variáveis preditoras não numéricas

- Variáveis categóricas ordinais podem ser transformadas diretamente em numéricas, mantendo a sua ordem
    - Por exemplo, a variável `BldgGrade` é uma categórica ordinal que representa o nível da casa e foi associada a um número inteiro

::: {.smaller-table}
```{python}
#| echo: false
pd.DataFrame({
    "Value": [1, 2, 5, 10, 12, 13],
    "Description": ["Cabin", "Substandard", "Fair", "Very good", "Luxury", "Mansion"]
})
```
:::

- Deve-se ter cuidado porque o valor numérico da variável também representa sua intensidade

## Avaliando modelo com mais variáveis

- $R^2$ melhorou (era $0.541$), mas nem sempre é o caso

```{python}
house_full = sm.OLS(house[outcome], X.assign(const=1))
results = house_full.fit()
print(results.summary())
```

## Correlação entre variáveis preditoras {.scrollable}

- Algo estranho no model: o coeficiente de `Bedrooms` foi negativo
    - Quanto mais quartos, menor o valor da casa?!

- Correlação entre preditores pode gerar resultados contraditórios

```{python}
X.corr()['Bedrooms'].sort_values(ascending=False)
```

## Correlação entre variáveis preditoras

- Removendo variáveis correlacionadas com `Bedrooms`
    - O coeficiente de `Bedrooms` passou a ser positivo

```{python}
X2 = X.filter(['Bedrooms', 'BldgGrade', 'PropertyType_Townhouse', 'PropertyType_Single Family', 'YrBuilt'])
house_mcol = sm.OLS(house[outcome], X2.assign(const=1))
results = house_mcol.fit()
print(results.summary())
```

## Variáveis com pouca significância no teste-t {.smaller-code-fold}

- Removendo `PropertyType_Single Family` com p-valor $<0.05$

```{python}
#| code-fold: true
X3 = X2.drop(columns=['PropertyType_Single Family'])
house_lm2 = sm.OLS(house[outcome], X3.assign(const=1))
results = house_lm2.fit()
print(results.summary())
```

## Problema da multicolinearidade

- Quando duas variáveis preditoras são linearmente dependentes, dizemos que elas são colineares (forte correlação linear)
    - Elas deixam de ser independentes entre si e ambas trazem essencialmente a mesma informação
    - Nenhuma pode contribuir significativamente para a variação de $y$ depois que a outra foi incluída
- A multicolinearidade afeta os resultados da regressão
    - Variáveis devem ser removidas até eliminar a multicolinearidade

## Problema da multicolinearidade {.scrollable}

- Precisamos encontrar a correlação entre vários pares $x_i$
    - Quando a correlação for alta devemos eliminar uma das variáveis do modelo e refazer os cálculos
    - Se a significância da regressão aumentar, então concluímos que a correlação forte estava causando o problema

::: {.smaller-table}
```{python}
X.corr()
```
:::

## Problema da multicolinearidade {.scrollable}

::: {.smaller-code-fold}
```{python}
#| code-fold: true

from scipy.stats import pearsonr
import matplotlib.pyplot as plt 

def corrfunc(x, y, ax=None, **kws):
    """Plot the correlation coefficient in the top left hand corner of a plot."""
    r, _ = pearsonr(x, y)
    ax = ax or plt.gca()
    ax.annotate(f'ρ = {r:.2f}', xy=(.2, .99), xycoords=ax.transAxes)

#g = sns.pairplot(X2, height=1.3)
#g.map_lower(corrfunc)
#plt.show()
```
:::

## Variável de confusão (_confounding_) {.smaller-code-fold}

- Uma variável importante que influencia a variável dependente (e algumas independentes) que não está no modelo
    - Exemplo: falta variável que represente a localização da casa, que pode influenciar no preço. Adicionando variável `ZipGroup` (5 regiões)

```{python}
#| code-fold: true

zip_groups = pd.DataFrame([
    *pd.DataFrame({
        'ZipCode': house['ZipCode'],
        'residual' : house[outcome] - house_lm.predict(house[predictors]),
    })
    .groupby(['ZipCode'])
    .apply(lambda x: {
        'ZipCode': x.iloc[0,0],
        'count': len(x),
        'median_residual': x.residual.median()
    })
]).sort_values('median_residual')
zip_groups['cum_count'] = np.cumsum(zip_groups['count'])
zip_groups['ZipGroup'] = pd.qcut(zip_groups['cum_count'], 5, labels=False, retbins=False)
zip_groups.head()

to_join = zip_groups[['ZipCode', 'ZipGroup']].set_index('ZipCode')
house = house.join(to_join, on='ZipCode')
house['ZipGroup'] = house['ZipGroup'].astype('category')

predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',
              'BldgGrade', 'PropertyType', 'ZipGroup']
outcome = 'AdjSalePrice'

X4 = pd.get_dummies(house[predictors], drop_first=True)

house_lm4 = sm.OLS(house[outcome], X4.assign(const=1))
results = house_lm4.fit()
print(results.summary())
```

## Interação entre variáveis {.smaller-code-fold}

- Podemos considerar a interação entre variáveis no modelo
    - Combinando variáveis `ZipGroup` (região) e `SqFtTotLiving` (área)
    - O metro quadrado custa mais em algumas áreas do que em outras


```{python}
#| code-fold: true

model = smf.ols(formula='AdjSalePrice ~  SqFtTotLiving*ZipGroup + SqFtLot + ' +
     'Bathrooms + Bedrooms + BldgGrade + PropertyType', data=house)
results = model.fit()
print(results.summary())
```

## Análise dos resíduos: Outliers {.smaller-code-fold}

- Podemos analisar os resíduos da regressão para mais diagnósticos
    - Analisando para um `ZipCode` específico:

```{python}
#| code-fold: true
house_98105 = house.loc[house['ZipCode'] == 98105, ]

predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',
              'BldgGrade']
outcome = 'AdjSalePrice'

house_outlier = sm.OLS(house_98105[outcome], house_98105[predictors].assign(const=1))
result_98105 = house_outlier.fit()
print(result_98105.summary())
```

## Análise dos resíduos: Outliers {.smaller-code-fold}

- Para identificar _outliers_ , podemos analisar estatísticas do resíduo padrão (resíduo dividido pelo erro padrão)

```{python}
influence = OLSInfluence(result_98105)
sresiduals = influence.resid_studentized_internal
print(f"Maior erro padrão (superestimado): {sresiduals.min()}. Erro absoluto: {result_98105.resid.loc[sresiduals.idxmin()]}")
```

- A maior superestimativa foi de 4 erros padrões
    - Analisando o _outlier_, aparenta ser um erro no registro dos dados

```{python}
outlier = house_98105.loc[sresiduals.idxmin(), :]
print('AdjSalePrice', outlier[outcome])
print(outlier[predictors])
```

## Propriedades desejáveis dos resíduos {.smaller-code-fold}

- **Homocedasticidade**: a variância dos resíduos deve se manter constante ao longo dos valores estimados
    - Visualização da _estimativa x resíduo_ indica que variância dos resíduos é maior para valores de casas muito baratas ou muito caras

```{python}
#| code-fold: true
fig, ax = plt.subplots(figsize=(6, 4))
sns.regplot(x=result_98105.fittedvalues, y=np.abs(result_98105.resid), 
            scatter_kws={'alpha': 0.25},
            line_kws={'color': 'C1'},
            lowess=True, ax=ax)
ax.set_xlabel('predicted')
ax.set_ylabel('abs(residual)')

plt.tight_layout()
plt.show()
```

## Propriedades desejáveis dos resíduos {.smaller-code-fold}

- **Normalidade**: idealmente, resíduos devem seguir distribuição normal
- Podemos visualizar o histograma do erro padrão dos resíduos
    - Aparenta ter cauda maior do que a normal, com leve viés à direita

```{python}
#| code-fold: true
fig, ax = plt.subplots(figsize=(6, 4))
pd.Series(influence.resid_studentized_internal).hist(ax=ax)
ax.set_xlabel('std. residual')
ax.set_ylabel('Frequency')


plt.tight_layout()
plt.show()
```

## Partial residual plot {.scrollable}

- Analisa visualmente a estimativa em relação a cada preditor
    - Plota o preditor no eixo $x$ e o resíduo parcial no eixo $y$
        - Relação do preço com `SqFtTotLiving` parece ser não linear

```{python}
fig = sm.graphics.plot_ccpr_grid(result_98105, fig=plt.figure(figsize=(10, 12)))
```
